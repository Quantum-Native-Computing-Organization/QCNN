{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "QCNN_test.ipynb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ],
      "metadata": {
        "id": "zQdCeMkzRBDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InhiigcvRFHd",
        "outputId": "b3fd5701-5215-4d82-fe88-baec75a93e0f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732166915365,
          "user_tz": -360,
          "elapsed": 242325,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane==0.35.1 (from -r requirements.txt (line 1))\n",
            "  Downloading PennyLane-0.35.1-py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting tensorflow==2.16.1 (from -r requirements.txt (line 2))\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting scikit-learn==1.4.2 (from -r requirements.txt (line 3))\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting medmnist==3.0.1 (from -r requirements.txt (line 4))\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch==2.2.2 (from -r requirements.txt (line 5))\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting autograd==1.6.2 (from -r requirements.txt (line 6))\n",
            "  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (3.4.2)\n",
            "Collecting rustworkx (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.10.2)\n",
            "Collecting appdirs (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting semantic-version>=2.7 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting autoray>=0.6.1 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (5.5.0)\n",
            "Collecting pennylane-lightning>=0.35 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.1->-r requirements.txt (line 2))\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.1->-r requirements.txt (line 2))\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.24.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (4.66.6)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (10.4.0)\n",
            "Collecting fire (from medmnist==3.0.1->-r requirements.txt (line 4))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.2->-r requirements.txt (line 5)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.2->-r requirements.txt (line 5))\n",
            "  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd==1.6.2->-r requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.13.0)\n",
            "INFO: pip is looking at multiple versions of pennylane-lightning to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pennylane-lightning>=0.35 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
            "  Downloading PennyLane_Lightning-0.38.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n",
            "  Downloading PennyLane_Lightning-0.37.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "  Downloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 5)) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from medmnist==3.0.1->-r requirements.txt (line 4))\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.19.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.1.2)\n",
            "Downloading PennyLane-0.35.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114248 sha256=f510cb0dd7f0c36de60736d3c5a10b3b68561768b850df3df64878b0759c7e48\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: appdirs, triton, semantic-version, rustworkx, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-dtypes, fire, autoray, autograd, tensorboard, scikit-learn, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, tensorflow, medmnist, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: autograd\n",
            "    Found existing installation: autograd 1.7.0\n",
            "    Uninstalling autograd-1.7.0:\n",
            "      Successfully uninstalled autograd-1.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.0+cu121\n",
            "    Uninstalling torchvision-0.20.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.0+cu121\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.16.1 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 autograd-1.6.2 autoray-0.7.0 fire-0.7.0 medmnist-3.0.1 ml-dtypes-0.3.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 pennylane-0.35.1 pennylane-lightning-0.36.0 rustworkx-0.15.1 scikit-learn-1.4.2 semantic-version-2.10.0 tensorboard-2.16.2 tensorflow-2.16.1 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "LNwOeT-nLj87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads and Processes the data that will be used in QCNN and Hierarchical Classifier Training\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers, losses\n",
        "pca32 = ['pca32-1', 'pca32-2', 'pca32-3', 'pca32-4']\n",
        "autoencoder32 = ['autoencoder32-1', 'autoencoder32-2', 'autoencoder32-3', 'autoencoder32-4']\n",
        "pca30 = ['pca30-1', 'pca30-2', 'pca30-3', 'pca30-4']\n",
        "autoencoder30 = ['autoencoder30-1', 'autoencoder30-2', 'autoencoder30-3', 'autoencoder30-4']\n",
        "pca16 = ['pca16-1', 'pca16-2', 'pca16-3', 'pca16-4', 'pca16-compact']\n",
        "autoencoder16 = ['autoencoder16-1', 'autoencoder16-2', 'autoencoder16-3', 'autoencoder16-4', 'autoencoder16-compact']\n",
        "pca12 = ['pca12-1', 'pca12-2', 'pca12-3', 'pca12-4']\n",
        "autoencoder12 = ['autoencoder12-1', 'autoencoder12-2', 'autoencoder12-3', 'autoencoder12-4']\n",
        "\n",
        "def data_load_and_process(dataset, classes=[0, 1], feature_reduction='resize256', binary=True):\n",
        "    if dataset == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    elif dataset == 'mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
        "\n",
        "    if classes == 'odd_even':\n",
        "        odd = [1, 3, 5, 7, 9]\n",
        "        X_train = x_train\n",
        "        X_test = x_test\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y in odd else 0 for y in y_train]\n",
        "            Y_test = [1 if y in odd else 0 for y in y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y in odd else -1 for y in y_train]\n",
        "            Y_test = [1 if y in odd else -1 for y in y_test]\n",
        "\n",
        "    elif classes == '>4':\n",
        "        greater = [5, 6, 7, 8, 9]\n",
        "        X_train = x_train\n",
        "        X_test = x_test\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y in greater else 0 for y in y_train]\n",
        "            Y_test = [1 if y in greater else 0 for y in y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y in greater else -1 for y in y_train]\n",
        "            Y_test = [1 if y in greater else -1 for y in y_test]\n",
        "\n",
        "    else:\n",
        "        x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
        "        x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
        "\n",
        "        X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
        "        Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
        "\n",
        "        if binary == False:\n",
        "            Y_train = [1 if y == classes[0] else 0 for y in Y_train]\n",
        "            Y_test = [1 if y == classes[0] else 0 for y in Y_test]\n",
        "        elif binary == True:\n",
        "            Y_train = [1 if y == classes[0] else -1 for y in Y_train]\n",
        "            Y_test = [1 if y == classes[0] else -1 for y in Y_test]\n",
        "\n",
        "    if feature_reduction == 'resize256':\n",
        "        X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
        "        X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
        "        X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "    elif feature_reduction == 'pca8' or feature_reduction in pca32 \\\n",
        "            or feature_reduction in pca30 or feature_reduction in pca16 or feature_reduction in pca12:\n",
        "\n",
        "        X_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
        "        X_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
        "        X_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
        "\n",
        "        if feature_reduction == 'pca8':\n",
        "            pca = PCA(8)\n",
        "        elif feature_reduction in pca32:\n",
        "            pca = PCA(32)\n",
        "        elif feature_reduction in pca30:\n",
        "            pca = PCA(30)\n",
        "        elif feature_reduction in pca16:\n",
        "            pca = PCA(16)\n",
        "        elif feature_reduction in pca12:\n",
        "            pca = PCA(12)\n",
        "\n",
        "\n",
        "        X_train = pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "\n",
        "        # Rescale for angle embedding\n",
        "        if feature_reduction == 'pca8' or feature_reduction == 'pca16-compact' or \\\n",
        "                feature_reduction in pca30 or feature_reduction in pca12:\n",
        "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())),\\\n",
        "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
        "        return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "    elif feature_reduction == 'autoencoder8' or feature_reduction in autoencoder32 \\\n",
        "            or feature_reduction in autoencoder30 or feature_reduction in autoencoder16 or feature_reduction in autoencoder12:\n",
        "        if feature_reduction == 'autoencoder8':\n",
        "            latent_dim = 8\n",
        "        elif feature_reduction in autoencoder32:\n",
        "            latent_dim = 32\n",
        "        elif feature_reduction in autoencoder30:\n",
        "            latent_dim = 30\n",
        "        elif feature_reduction in autoencoder16:\n",
        "            latent_dim = 16\n",
        "        elif feature_reduction in autoencoder12:\n",
        "            latent_dim = 12\n",
        "\n",
        "\n",
        "\n",
        "        class Autoencoder(Model):\n",
        "            def __init__(self, latent_dim):\n",
        "                super(Autoencoder, self).__init__()\n",
        "                self.latent_dim = latent_dim\n",
        "                self.encoder = tf.keras.Sequential([\n",
        "                    layers.Flatten(),\n",
        "                    layers.Dense(latent_dim, activation='relu'),\n",
        "                ])\n",
        "                self.decoder = tf.keras.Sequential([\n",
        "                    layers.Dense(784, activation='sigmoid'),\n",
        "                    layers.Reshape((28, 28))\n",
        "                ])\n",
        "\n",
        "            def call(self, x):\n",
        "                encoded = self.encoder(x)\n",
        "                decoded = self.decoder(encoded)\n",
        "                return decoded\n",
        "\n",
        "        autoencoder = Autoencoder(latent_dim)\n",
        "\n",
        "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "        autoencoder.fit(X_train, X_train,\n",
        "                        epochs=10,\n",
        "                        shuffle=True,\n",
        "                        validation_data=(X_test, X_test))\n",
        "\n",
        "        X_train, X_test = autoencoder.encoder(X_train).numpy(), autoencoder.encoder(X_test).numpy()\n",
        "\n",
        "        # Rescale for Angle Embedding\n",
        "        # Note this is not a rigorous rescaling method\n",
        "        if feature_reduction == 'autoencoder8' or feature_reduction == 'autoencoder16-compact' or\\\n",
        "                feature_reduction in autoencoder30 or feature_reduction in autoencoder12:\n",
        "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())), \\\n",
        "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
        "\n",
        "        return X_train, X_test, Y_train, Y_test\n"
      ],
      "metadata": {
        "id": "x6RCuHMpLjjV",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167323473,
          "user_tz": -360,
          "elapsed": 13759,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Angular_hybrid"
      ],
      "metadata": {
        "id": "039T2w4iSRab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an implementation of an alternative Mottonen State Preparation to avoid normalization problem.\n",
        "import pennylane as qml\n",
        "\n",
        "# 3 bits of information is embedded in 2 wires\n",
        "def Angular_Hybrid_2(X, wires):\n",
        "    qml.RY(X[0], wires=wires[0])\n",
        "\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
        "\n",
        "# 15 bits of information is embedded in 4 wires\n",
        "def Angular_Hybrid_4(X, wires):\n",
        "    qml.RY(X[0], wires=wires[0])\n",
        "\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
        "\n",
        "    qml.RY(X[3], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[1], wires[2]])\n",
        "    qml.RY(X[4], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[0], wires[2]])\n",
        "    qml.RY(X[5], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[1], wires[2]])\n",
        "    qml.RY(X[6], wires=wires[2])\n",
        "    qml.CNOT(wires=[wires[0], wires[2]])\n",
        "\n",
        "    qml.RY(X[7], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[8], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[1], wires[3]])\n",
        "    qml.RY(X[9], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[10], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[0], wires[3]])\n",
        "    qml.RY(X[11], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[12], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[1], wires[3]])\n",
        "    qml.RY(X[13], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[2], wires[3]])\n",
        "    qml.RY(X[14], wires=wires[3])\n",
        "    qml.CNOT(wires=[wires[0], wires[3]])"
      ],
      "metadata": {
        "id": "e8bQcfcXSW05",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167330757,
          "user_tz": -360,
          "elapsed": 2810,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Unitary"
      ],
      "metadata": {
        "id": "_Yg25yMmQjAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This module contains the set of unitary ansatze that will be used to benchmark the performances of Quantum Convolutional Neural Network (QCNN) in QCNN.ipynb module\n",
        "import pennylane as qml\n",
        "\n",
        "# Unitary Ansatze for Convolutional Layer\n",
        "def U_TTN(params, wires):  # 2 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_5(params, wires):  # 10 params\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "    qml.RZ(params[2], wires=wires[0])\n",
        "    qml.RZ(params[3], wires=wires[1])\n",
        "    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n",
        "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[6], wires=wires[0])\n",
        "    qml.RX(params[7], wires=wires[1])\n",
        "    qml.RZ(params[8], wires=wires[0])\n",
        "    qml.RZ(params[9], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_6(params, wires):  # 10 params\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "    qml.RZ(params[2], wires=wires[0])\n",
        "    qml.RZ(params[3], wires=wires[1])\n",
        "    qml.CRX(params[4], wires=[wires[1], wires[0]])\n",
        "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[6], wires=wires[0])\n",
        "    qml.RX(params[7], wires=wires[1])\n",
        "    qml.RZ(params[8], wires=wires[0])\n",
        "    qml.RZ(params[9], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_9(params, wires):  # 2 params\n",
        "    qml.Hadamard(wires=wires[0])\n",
        "    qml.Hadamard(wires=wires[1])\n",
        "    qml.CZ(wires=[wires[0], wires[1]])\n",
        "    qml.RX(params[0], wires=wires[0])\n",
        "    qml.RX(params[1], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_13(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[3], wires=wires[0])\n",
        "    qml.RY(params[4], wires=wires[1])\n",
        "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_14(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CRX(params[2], wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[3], wires=wires[0])\n",
        "    qml.RY(params[4], wires=wires[1])\n",
        "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_15(params, wires):  # 4 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[2], wires=wires[0])\n",
        "    qml.RY(params[3], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "\n",
        "\n",
        "def U_SO4(params, wires):  # 6 params\n",
        "    qml.RY(params[0], wires=wires[0])\n",
        "    qml.RY(params[1], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[2], wires=wires[0])\n",
        "    qml.RY(params[3], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[4], wires=wires[0])\n",
        "    qml.RY(params[5], wires=wires[1])\n",
        "\n",
        "\n",
        "def U_SU4(params, wires): # 15 params\n",
        "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
        "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.RY(params[6], wires=wires[0])\n",
        "    qml.RZ(params[7], wires=wires[1])\n",
        "    qml.CNOT(wires=[wires[1], wires[0]])\n",
        "    qml.RY(params[8], wires=wires[0])\n",
        "    qml.CNOT(wires=[wires[0], wires[1]])\n",
        "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
        "    qml.U3(params[12], params[13], params[14], wires=wires[1])\n",
        "\n",
        "# Pooling Layer\n",
        "\n",
        "def Pooling_ansatz1(params, wires): #2 params\n",
        "    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
        "    qml.PauliX(wires=wires[0])\n",
        "    qml.CRX(params[1], wires=[wires[0], wires[1]])\n",
        "\n",
        "def Pooling_ansatz2(wires): #0 params\n",
        "    qml.CRZ(wires=[wires[0], wires[1]])\n",
        "\n",
        "def Pooling_ansatz3(*params, wires): #3 params\n",
        "    qml.CRot(*params, wires=[wires[0], wires[1]])"
      ],
      "metadata": {
        "id": "-9qnNHIOQnps",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167330757,
          "user_tz": -360,
          "elapsed": 1,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedding"
      ],
      "metadata": {
        "id": "MULojT0GQlAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is an implementation of data_embedding function used for 8 qubits Quantum Convolutional Neural Network (QCNN)\n",
        "# and Hierarchical Quantum Classifier circuit.\n",
        "import pennylane as qml\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
        "from pennylane.templates.state_preparations import MottonenStatePreparation\n",
        "import numpy as np\n",
        "\n",
        "def data_embedding(X, embedding_type='Amplitude'):\n",
        "    if embedding_type == 'Amplitude':\n",
        "        AmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
        "    elif embedding_type == 'Angle':\n",
        "        AngleEmbedding(X, wires=range(8), rotation='Y')\n",
        "    elif embedding_type == 'Angle-compact':\n",
        "        AngleEmbedding(X[:8], wires=range(8), rotation='X')\n",
        "        AngleEmbedding(X[8:16], wires=range(8), rotation='Y')\n",
        "\n",
        "    # Hybrid Direct Embedding (HDE)\n",
        "    elif embedding_type == 'Amplitude-Hybrid4-1' or embedding_type == 'Amplitude-Hybrid4-2' or \\\n",
        "            embedding_type == 'Amplitude-Hybrid4-3' or embedding_type == 'Amplitude-Hybrid4-4':\n",
        "        X1 = X[:2 ** 4]\n",
        "        X2 = X[2 ** 4:2 ** 5]\n",
        "        norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
        "        X1, X2 = X1 / norm_X1, X2 / norm_X2\n",
        "\n",
        "        if embedding_type == 'Amplitude-Hybrid4-1':\n",
        "            MottonenStatePreparation(X1, wires=[0, 1, 2, 3])\n",
        "            MottonenStatePreparation(X2, wires=[4, 5, 6, 7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-2':\n",
        "            MottonenStatePreparation(X1, wires=[0, 2, 4, 6])\n",
        "            MottonenStatePreparation(X2, wires=[1, 3, 5, 7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-3':\n",
        "            MottonenStatePreparation(X1, wires=[0, 1, 6, 7])\n",
        "            MottonenStatePreparation(X2, wires=[2, 3, 4, 5])\n",
        "        elif embedding_type == 'Amplitude-Hybrid4-4':\n",
        "            MottonenStatePreparation(X1, wires=[0, 3, 4, 7])\n",
        "            MottonenStatePreparation(X2, wires=[1, 2, 5, 6])\n",
        "\n",
        "    elif embedding_type == 'Amplitude-Hybrid2-1' or embedding_type == 'Amplitude-Hybrid2-2' \\\n",
        "            or embedding_type == 'Amplitude-Hybrid2-3' or embedding_type == 'Amplitude-Hybrid2-4':\n",
        "        X1 = X[:4]\n",
        "        X2 = X[4:8]\n",
        "        X3 = X[8:12]\n",
        "        X4 = X[12:16]\n",
        "        norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(X3), np.linalg.norm(\n",
        "            X4)\n",
        "        X1, X2, X3, X4 = X1 / norm_X1, X2 / norm_X2, X3 / norm_X3, X4 / norm_X4\n",
        "\n",
        "        if embedding_type == 'Amplitude-Hybrid2-1':\n",
        "            MottonenStatePreparation(X1, wires=[0,1])\n",
        "            MottonenStatePreparation(X2, wires=[2,3])\n",
        "            MottonenStatePreparation(X3, wires=[4,5])\n",
        "            MottonenStatePreparation(X4, wires=[6,7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-2':\n",
        "            MottonenStatePreparation(X1, wires=[0,4])\n",
        "            MottonenStatePreparation(X2, wires=[1,5])\n",
        "            MottonenStatePreparation(X3, wires=[2,6])\n",
        "            MottonenStatePreparation(X4, wires=[3,7])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-3':\n",
        "            MottonenStatePreparation(X1, wires=[0,7])\n",
        "            MottonenStatePreparation(X2, wires=[1,6])\n",
        "            MottonenStatePreparation(X3, wires=[2,5])\n",
        "            MottonenStatePreparation(X4, wires=[3,4])\n",
        "        elif embedding_type == 'Amplitude-Hybrid2-4':\n",
        "            MottonenStatePreparation(X1, wires=[0,2])\n",
        "            MottonenStatePreparation(X2, wires=[1,3])\n",
        "            MottonenStatePreparation(X3, wires=[4,6])\n",
        "            MottonenStatePreparation(X4, wires=[5,7])\n",
        "\n",
        "    # Hybrid Angle Embedding (HAE)\n",
        "    elif embedding_type == 'Angular-Hybrid4-1' or embedding_type == 'Angular-Hybrid4-2' or \\\n",
        "            embedding_type == 'Angular-Hybrid4-3' or embedding_type == 'Angular-Hybrid4-4':\n",
        "        N = 15 # 15 classical data in 4 qubits\n",
        "        X1 = X[:N]\n",
        "        X2 = X[N:2*N]\n",
        "\n",
        "        if embedding_type == 'Angular-Hybrid4-1':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 1, 2, 3])\n",
        "            Angular_Hybrid_4(X2, wires=[4, 5, 6, 7])\n",
        "        elif embedding_type == 'Angular-Hybrid4-2':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 2, 4, 6])\n",
        "            Angular_Hybrid_4(X2, wires=[1, 3, 5, 7])\n",
        "        elif embedding_type == 'Angular-Hybrid4-3':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 1, 6, 7])\n",
        "            Angular_Hybrid_4(X2, wires=[2, 3, 4, 5])\n",
        "        elif embedding_type == 'Angular-Hybrid4-4':\n",
        "            Angular_Hybrid_4(X1, wires=[0, 3, 4, 7])\n",
        "            Angular_Hybrid_4(X2, wires=[1, 2, 5, 6])\n",
        "\n",
        "    elif embedding_type == 'Angular-Hybrid2-1' or embedding_type == 'Angular-Hybrid2-2' \\\n",
        "            or embedding_type == 'Angular-Hybrid2-3' or embedding_type == 'Angular-Hybrid2-4':\n",
        "        N = 3  # 3 classical bits in 2 qubits\n",
        "        X1 = X[:N]\n",
        "        X2 = X[N:2*N]\n",
        "        X3 = X[2*N:3*N]\n",
        "        X4 = X[3*N:4*N]\n",
        "\n",
        "        if embedding_type == 'Angular-Hybrid2-1':\n",
        "            Angular_Hybrid_2(X1, wires=[0,1])\n",
        "            Angular_Hybrid_2(X2, wires=[2,3])\n",
        "            Angular_Hybrid_2(X3, wires=[4,5])\n",
        "            Angular_Hybrid_2(X4, wires=[6,7])\n",
        "        elif embedding_type == 'Angular-Hybrid2-2':\n",
        "            Angular_Hybrid_2(X1, wires=[0,4])\n",
        "            Angular_Hybrid_2(X2, wires=[1,5])\n",
        "            Angular_Hybrid_2(X3, wires=[2,6])\n",
        "            Angular_Hybrid_2(X4, wires=[3,7])\n",
        "        elif embedding_type == 'Angular-Hybrid2-3':\n",
        "            Angular_Hybrid_2(X1, wires=[0,7])\n",
        "            Angular_Hybrid_2(X2, wires=[1,6])\n",
        "            Angular_Hybrid_2(X3, wires=[2,5])\n",
        "            Angular_Hybrid_2(X4, wires=[3,4])\n",
        "        elif embedding_type == 'Angular-Hybrid2-4':\n",
        "            Angular_Hybrid_2(X1, wires=[0,2])\n",
        "            Angular_Hybrid_2(X2, wires=[1,3])\n",
        "            Angular_Hybrid_2(X3, wires=[4,6])\n",
        "            Angular_Hybrid_2(X4, wires=[5,7])"
      ],
      "metadata": {
        "id": "37FbHsvrQwtN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167336404,
          "user_tz": -360,
          "elapsed": 712,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#QCNN Circuit"
      ],
      "metadata": {
        "id": "Ao0qIpOENFZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "\n",
        "\n",
        "# Quantum Circuits for Convolutional layers\n",
        "def conv_layer1(U, params):\n",
        "    U(params, wires=[0, 7])\n",
        "    for i in range(0, 8, 2):\n",
        "        U(params, wires=[i, i + 1])\n",
        "    for i in range(1, 7, 2):\n",
        "        U(params, wires=[i, i + 1])\n",
        "def conv_layer2(U, params):\n",
        "    U(params, wires=[0, 6])\n",
        "    U(params, wires=[0, 2])\n",
        "    U(params, wires=[4, 6])\n",
        "    U(params, wires=[2, 4])\n",
        "def conv_layer3(U, params):\n",
        "    U(params, wires=[0,4])\n",
        "\n",
        "# Quantum Circuits for Pooling layers\n",
        "def pooling_layer1(V, params):\n",
        "    for i in range(0, 8, 2):\n",
        "        V(params, wires=[i + 1, i])\n",
        "def pooling_layer2(V, params):\n",
        "    V(params, wires=[2,0])\n",
        "    V(params, wires=[6,4])\n",
        "def pooling_layer3(V, params):\n",
        "    V(params, wires=[0,4])\n",
        "\n",
        "\n",
        "\n",
        "def QCNN_structure(U, params, U_params):\n",
        "    param1 = params[0:U_params]\n",
        "    param2 = params[U_params: 2 * U_params]\n",
        "    param3 = params[2 * U_params: 3 * U_params]\n",
        "    param4 = params[3 * U_params: 3 * U_params + 2]\n",
        "    param5 = params[3 * U_params + 2: 3 * U_params + 4]\n",
        "    param6 = params[3 * U_params + 4: 3 * U_params + 6]\n",
        "\n",
        "    # Pooling Ansatz1 is used by default\n",
        "    conv_layer1(U, param1)\n",
        "    pooling_layer1(Pooling_ansatz1, param4)\n",
        "    conv_layer2(U, param2)\n",
        "    pooling_layer2(Pooling_ansatz1, param5)\n",
        "    conv_layer3(U, param3)\n",
        "    pooling_layer3(Pooling_ansatz1, param6)\n",
        "\n",
        "\n",
        "def QCNN_structure_without_pooling(U, params, U_params):\n",
        "    param1 = params[0:U_params]\n",
        "    param2 = params[U_params: 2 * U_params]\n",
        "    param3 = params[2 * U_params: 3 * U_params]\n",
        "\n",
        "    conv_layer1(U, param1)\n",
        "    conv_layer2(U, param2)\n",
        "    conv_layer3(U, param3)\n",
        "\n",
        "def QCNN_1D_circuit(U, params, U_params):\n",
        "    param1 = params[0: U_params]\n",
        "    param2 = params[U_params: 2*U_params]\n",
        "    param3 = params[2*U_params: 3*U_params]\n",
        "\n",
        "    for i in range(0, 8, 2):\n",
        "        U(param1, wires=[i, i + 1])\n",
        "    for i in range(1, 7, 2):\n",
        "        U(param1, wires=[i, i + 1])\n",
        "\n",
        "    U(param2, wires=[2,3])\n",
        "    U(param2, wires=[4,5])\n",
        "    U(param3, wires=[3,4])\n",
        "\n",
        "\n",
        "\n",
        "dev = qml.device('default.qubit', wires = 8)\n",
        "@qml.qnode(dev)\n",
        "def QCNN(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
        "\n",
        "\n",
        "    # Data Embedding\n",
        "    data_embedding(X, embedding_type=embedding_type)\n",
        "\n",
        "    # Quantum Convolutional Neural Network\n",
        "    if U == 'U_TTN':\n",
        "        QCNN_structure(U_TTN, params, U_params)\n",
        "    elif U == 'U_5':\n",
        "        QCNN_structure(U_5, params, U_params)\n",
        "    elif U == 'U_6':\n",
        "        QCNN_structure(U_6, params, U_params)\n",
        "    elif U == 'U_9':\n",
        "        QCNN_structure(U_9, params, U_params)\n",
        "    elif U == 'U_13':\n",
        "        QCNN_structure(U_13, params, U_params)\n",
        "    elif U == 'U_14':\n",
        "        QCNN_structure(U_14, params, U_params)\n",
        "    elif U == 'U_15':\n",
        "        QCNN_structure(U_15, params, U_params)\n",
        "    elif U == 'U_SO4':\n",
        "        QCNN_structure(U_SO4, params, U_params)\n",
        "    elif U == 'U_SU4':\n",
        "        QCNN_structure(U_SU4, params, U_params)\n",
        "    elif U == 'U_SU4_no_pooling':\n",
        "        QCNN_structure_without_pooling(U_SU4, params, U_params)\n",
        "    elif U == 'U_SU4_1D':\n",
        "        QCNN_1D_circuit(U_SU4, params, U_params)\n",
        "    elif U == 'U_9_1D':\n",
        "        QCNN_1D_circuit(U_9, params, U_params)\n",
        "    else:\n",
        "        print(\"Invalid Unitary Ansatze\")\n",
        "        return False\n",
        "\n",
        "    if cost_fn == 'mse':\n",
        "        result = qml.expval(qml.PauliZ(4))\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        result = qml.probs(wires=4)\n",
        "    return result"
      ],
      "metadata": {
        "id": "ywqqn0KbNf80",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167622570,
          "user_tz": -360,
          "elapsed": 734,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hierarchical Circuit"
      ],
      "metadata": {
        "id": "p2I6ICMKNIG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementaion of Hierarchical Quantum Classifier Structure.\n",
        "import pennylane as qml\n",
        "\n",
        "\n",
        "dev_TTN = qml.device('default.qubit', wires=8)\n",
        "\n",
        "def Hierarchical_structure(U, params, U_params):\n",
        "    param1 = params[0 * U_params:1 * U_params]\n",
        "    param2 = params[1 * U_params:2 * U_params]\n",
        "    param3 = params[2 * U_params:3 * U_params]\n",
        "    param4 = params[3 * U_params:4 * U_params]\n",
        "    param5 = params[4 * U_params:5 * U_params]\n",
        "    param6 = params[5 * U_params:6 * U_params]\n",
        "    param7 = params[6 * U_params:7 * U_params]\n",
        "\n",
        "    # 1st Layer\n",
        "    U(param1, wires=[0, 1])\n",
        "    U(param2, wires=[2, 3])\n",
        "    U(param3, wires=[4, 5])\n",
        "    U(param4, wires=[6, 7])\n",
        "    # 2nd Layer\n",
        "    U(param5, wires=[1, 3])\n",
        "    U(param6, wires=[5, 7])\n",
        "    # 3rd Layer\n",
        "    U(param7, wires=[3, 7])\n",
        "\n",
        "\n",
        "\n",
        "@qml.qnode(dev_TTN)\n",
        "def Hierarchical_classifier(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
        "    data_embedding(X, embedding_type=embedding_type)\n",
        "    if U == 'U_TTN':\n",
        "        Hierarchical_structure(U_TTN, params, U_params)\n",
        "    elif U == 'U_5':\n",
        "        Hierarchical_structure(U_5, params, U_params)\n",
        "    elif U == 'U_6':\n",
        "        Hierarchical_structure(U_6, params, U_params)\n",
        "    elif U == 'U_9':\n",
        "        Hierarchical_structure(U_9, params, U_params)\n",
        "    elif U == 'U_13':\n",
        "        Hierarchical_structure(U_13, params, U_params)\n",
        "    elif U == 'U_14':\n",
        "        Hierarchical_structure(U_14, params, U_params)\n",
        "    elif U == 'U_15':\n",
        "        Hierarchical_structure(U_15, params, U_params)\n",
        "    elif U == 'U_SO4':\n",
        "        Hierarchical_structure(U_SO4, params, U_params)\n",
        "    elif U == 'U_SU4':\n",
        "        Hierarchical_structure(U_SU4, params, U_params)\n",
        "    else:\n",
        "        print(\"Invalid Unitary Ansatz\")\n",
        "        return False\n",
        "    if cost_fn == 'mse':\n",
        "        result = qml.expval(qml.PauliZ(7))\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        result = qml.probs(wires=7)\n",
        "    return result"
      ],
      "metadata": {
        "id": "73fa3h4JNkmX",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167349339,
          "user_tz": -360,
          "elapsed": 770,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "Mh9YDNmfLVL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of Quantum circuit training procedure\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import autograd.numpy as anp\n",
        "\n",
        "def square_loss(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        loss = loss + (l - p) ** 2\n",
        "    loss = loss / len(labels)\n",
        "    return loss\n",
        "\n",
        "def cross_entropy(labels, predictions):\n",
        "    loss = 0\n",
        "    for l, p in zip(labels, predictions):\n",
        "        c_entropy = l * (anp.log(p[l])) + (1 - l) * anp.log(1 - p[1 - l])\n",
        "        loss = loss + c_entropy\n",
        "    return -1 * loss\n",
        "\n",
        "def cost(params, X, Y, U, U_params, embedding_type, circuit, cost_fn):\n",
        "    if circuit == 'QCNN':\n",
        "        predictions = [QCNN(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
        "    elif circuit == 'Hierarchical':\n",
        "        predictions = [Hierarchical_classifier(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
        "\n",
        "    if cost_fn == 'mse':\n",
        "        loss = square_loss(Y, predictions)\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        loss = cross_entropy(Y, predictions)\n",
        "    return loss\n",
        "\n",
        "# Circuit training parameters\n",
        "steps = 200\n",
        "learning_rate = 0.01\n",
        "batch_size = 25\n",
        "def circuit_training(X_train, Y_train, U, U_params, embedding_type, circuit, cost_fn):\n",
        "    if circuit == 'QCNN':\n",
        "        if U == 'U_SU4_no_pooling' or U == 'U_SU4_1D' or U == 'U_9_1D':\n",
        "            total_params = U_params * 3\n",
        "        else:\n",
        "            total_params = U_params * 3 + 2 * 3\n",
        "    elif circuit == 'Hierarchical':\n",
        "        total_params = U_params * 7\n",
        "\n",
        "    #params = np.random.randn(total_params, requires_grad=True)\n",
        "    params = tf.Variable(tf.random.normal(shape=(total_params,)), trainable=True)\n",
        "    opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
        "    loss_history = []\n",
        "\n",
        "    for it in range(steps):\n",
        "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
        "        X_batch = [X_train[i] for i in batch_index]\n",
        "        Y_batch = [Y_train[i] for i in batch_index]\n",
        "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit, cost_fn),\n",
        "                                                     params)\n",
        "        loss_history.append(cost_new)\n",
        "        if it % 10 == 0:\n",
        "            print(\"iteration: \", it, \" cost: \", cost_new)\n",
        "    return loss_history, params\n",
        "\n"
      ],
      "metadata": {
        "id": "dbsaTU7ELVwq",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167353250,
          "user_tz": -360,
          "elapsed": 736,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking"
      ],
      "metadata": {
        "id": "tmMk8E8PLDfb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xczHohbTLB-c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732167393205,
          "user_tz": -360,
          "elapsed": 717,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def accuracy_test(predictions, labels, cost_fn, binary = True):\n",
        "    if cost_fn == 'mse':\n",
        "        if binary == True:\n",
        "            acc = 0\n",
        "            for l, p in zip(labels, predictions):\n",
        "                if np.abs(l - p) < 1:\n",
        "                    acc = acc + 1\n",
        "            return acc / len(labels)\n",
        "\n",
        "        else:\n",
        "            acc = 0\n",
        "            for l, p in zip(labels, predictions):\n",
        "                if np.abs(l - p) < 0.5:\n",
        "                    acc = acc + 1\n",
        "            return acc / len(labels)\n",
        "\n",
        "    elif cost_fn == 'cross_entropy':\n",
        "        acc = 0\n",
        "        for l,p in zip(labels, predictions):\n",
        "            if p[0] > p[1]:\n",
        "                P = 0\n",
        "            else:\n",
        "                P = 1\n",
        "            if P == l:\n",
        "                acc = acc + 1\n",
        "        return acc / len(labels)\n",
        "\n",
        "\n",
        "def Encoding_to_Embedding(Encoding):\n",
        "    # Amplitude Embedding / Angle Embedding\n",
        "    if Encoding == 'resize256':\n",
        "        Embedding = 'Amplitude'\n",
        "    elif Encoding == 'pca8':\n",
        "        Embedding = 'Angle'\n",
        "    elif Encoding == 'autoencoder8':\n",
        "        Embedding = 'Angle'\n",
        "\n",
        "    # Amplitude Hybrid Embedding\n",
        "    # 4 qubit block\n",
        "    elif Encoding == 'pca32-1':\n",
        "        Embedding = 'Amplitude-Hybrid4-1'\n",
        "    elif Encoding == 'autoencoder32-1':\n",
        "        Embedding = 'Amplitude-Hybrid4-1'\n",
        "\n",
        "    elif Encoding == 'pca32-2':\n",
        "        Embedding = 'Amplitude-Hybrid4-2'\n",
        "    elif Encoding == 'autoencoder32-2':\n",
        "        Embedding = 'Amplitude-Hybrid4-2'\n",
        "\n",
        "    elif Encoding == 'pca32-3':\n",
        "        Embedding = 'Amplitude-Hybrid4-3'\n",
        "    elif Encoding == 'autoencoder32-3':\n",
        "        Embedding = 'Amplitude-Hybrid4-3'\n",
        "\n",
        "    elif Encoding == 'pca32-4':\n",
        "        Embedding = 'Amplitude-Hybrid4-4'\n",
        "    elif Encoding == 'autoencoder32-4':\n",
        "        Embedding = 'Amplitude-Hybrid4-4'\n",
        "\n",
        "    # 2 qubit block\n",
        "    elif Encoding == 'pca16-1':\n",
        "        Embedding = 'Amplitude-Hybrid2-1'\n",
        "    elif Encoding == 'autoencoder16-1':\n",
        "        Embedding = 'Amplitude-Hybrid2-1'\n",
        "\n",
        "    elif Encoding == 'pca16-2':\n",
        "        Embedding = 'Amplitude-Hybrid2-2'\n",
        "    elif Encoding == 'autoencoder16-2':\n",
        "        Embedding = 'Amplitude-Hybrid2-2'\n",
        "\n",
        "    elif Encoding == 'pca16-3':\n",
        "        Embedding = 'Amplitude-Hybrid2-3'\n",
        "    elif Encoding == 'autoencoder16-3':\n",
        "        Embedding = 'Amplitude-Hybrid2-3'\n",
        "\n",
        "    elif Encoding == 'pca16-4':\n",
        "        Embedding = 'Amplitude-Hybrid2-4'\n",
        "    elif Encoding == 'autoencoder16-4':\n",
        "        Embedding = 'Amplitude-Hybrid2-4'\n",
        "\n",
        "    # Angular HybridEmbedding\n",
        "    # 4 qubit block\n",
        "    elif Encoding == 'pca30-1':\n",
        "        Embedding = 'Angular-Hybrid4-1'\n",
        "    elif Encoding == 'autoencoder30-1':\n",
        "        Embedding = 'Angular-Hybrid4-1'\n",
        "\n",
        "    elif Encoding == 'pca30-2':\n",
        "        Embedding = 'Angular-Hybrid4-2'\n",
        "    elif Encoding == 'autoencoder30-2':\n",
        "        Embedding = 'Angular-Hybrid4-2'\n",
        "\n",
        "    elif Encoding == 'pca30-3':\n",
        "        Embedding = 'Angular-Hybrid4-3'\n",
        "    elif Encoding == 'autoencoder30-3':\n",
        "        Embedding = 'Angular-Hybrid4-3'\n",
        "\n",
        "    elif Encoding == 'pca30-4':\n",
        "        Embedding = 'Angular-Hybrid4-4'\n",
        "    elif Encoding == 'autoencoder30-4':\n",
        "        Embedding = 'Angular-Hybrid4-4'\n",
        "\n",
        "    # 2 qubit block\n",
        "    elif Encoding == 'pca12-1':\n",
        "        Embedding = 'Angular-Hybrid2-1'\n",
        "    elif Encoding == 'autoencoder12-1':\n",
        "        Embedding = 'Angular-Hybrid2-1'\n",
        "\n",
        "    elif Encoding == 'pca12-2':\n",
        "        Embedding = 'Angular-Hybrid2-2'\n",
        "    elif Encoding == 'autoencoder12-2':\n",
        "        Embedding = 'Angular-Hybrid2-2'\n",
        "\n",
        "    elif Encoding == 'pca12-3':\n",
        "        Embedding = 'Angular-Hybrid2-3'\n",
        "    elif Encoding == 'autoencoder12-3':\n",
        "        Embedding = 'Angular-Hybrid2-3'\n",
        "\n",
        "    elif Encoding == 'pca12-4':\n",
        "        Embedding = 'Angular-Hybrid2-4'\n",
        "    elif Encoding == 'autoencoder12-4':\n",
        "        Embedding = 'Angular-Hybrid2-4'\n",
        "\n",
        "    # Two Gates Compact Encoding\n",
        "    elif Encoding == 'pca16-compact':\n",
        "        Embedding = 'Angle-compact'\n",
        "    elif Encoding == 'autoencoder16-compact':\n",
        "        Embedding = 'Angle-compact'\n",
        "    return Embedding\n",
        "\n",
        "\n",
        "def Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit, cost_fn, binary=True):\n",
        "    I = len(Unitaries)\n",
        "    J = len(Encodings)\n",
        "\n",
        "    for i in range(I):\n",
        "        for j in range(J):\n",
        "            f = open('Result/result.txt', 'a')\n",
        "            U = Unitaries[i]\n",
        "            U_params = U_num_params[i]\n",
        "            Encoding = Encodings[j]\n",
        "            Embedding = Encoding_to_Embedding(Encoding)\n",
        "\n",
        "            X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
        "                                                                          feature_reduction=Encoding, binary=binary)\n",
        "\n",
        "            print(\"\\n\")\n",
        "            print(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
        "            loss_history, trained_params = circuit_training(X_train, Y_train, U, U_params, Embedding, circuit, cost_fn)\n",
        "\n",
        "            if circuit == 'QCNN':\n",
        "                predictions = [QCNN(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
        "            elif circuit == 'Hierarchical':\n",
        "                predictions = [Hierarchical_classifier(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
        "\n",
        "            accuracy = accuracy_test(predictions, Y_test, cost_fn, binary)\n",
        "            print(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
        "\n",
        "            f.write(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
        "            f.write(\"\\n\")\n",
        "            f.write(str(loss_history))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"\\n\")\n",
        "    f.close()\n",
        "\n",
        "def Data_norm(dataset, classes, Encodings, binary=True):\n",
        "    J = len(Encodings)\n",
        "    Num_data = 10000\n",
        "\n",
        "    f = open('Result/data_norm.txt', 'a')\n",
        "\n",
        "    for j in range(J):\n",
        "        Encoding = Encodings[j]\n",
        "\n",
        "        X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
        "                                                                          feature_reduction=Encoding, binary=binary)\n",
        "\n",
        "        if Encoding == 'pca32-3' or Encoding == 'autoencoder32-3':\n",
        "            norms_X1 = []\n",
        "            norms_X2 = []\n",
        "            for i in range(Num_data):\n",
        "                index = np.random.randint(0, len(X_train))\n",
        "                X = X_train[index]\n",
        "\n",
        "                X1 = X[:2 ** 4]\n",
        "                X2 = X[2 ** 4:2 ** 5]\n",
        "                norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
        "                norms_X1.append(norm_X1)\n",
        "                norms_X2.append(norm_X2)\n",
        "\n",
        "            norms_X1, norms_X2 = np.array(norms_X1), np.array(norms_X2)\n",
        "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
        "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
        "\n",
        "            if Encoding == 'pca32-3':\n",
        "                f.write(\"PCA32 Encoding\\n\")\n",
        "            elif Encoding == 'autoencoder32-3':\n",
        "                f.write(\"autoencoder32 Encoding\\n\")\n",
        "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        elif Encoding == 'pca16' or Encoding == 'autoencoder16':\n",
        "            norms_X1 = []\n",
        "            norms_X2 = []\n",
        "            norms_X3 = []\n",
        "            norms_X4 = []\n",
        "            for i in range(Num_data):\n",
        "                index = np.random.randint(0, len(X_train))\n",
        "                X = X_train[index]\n",
        "\n",
        "                X1 = X[:4]\n",
        "                X2 = X[4:8]\n",
        "                X3 = X[8:12]\n",
        "                X4 = X[12:16]\n",
        "                norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(\n",
        "                    X3), np.linalg.norm(X4)\n",
        "\n",
        "                norms_X1.append(norm_X1)\n",
        "                norms_X2.append(norm_X2)\n",
        "                norms_X3.append(norm_X3)\n",
        "                norms_X4.append(norm_X4)\n",
        "\n",
        "            norms_X1, norms_X2, norms_X3, norms_X4 = np.array(norms_X1), np.array(norms_X2), np.array(norms_X3), np.array(norms_X4)\n",
        "\n",
        "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
        "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
        "            mean_X3, stdev_X3 = np.mean(norms_X3), np.std(norms_X3)\n",
        "            mean_X4, stdev_X4 = np.mean(norms_X4), np.std(norms_X4)\n",
        "\n",
        "            if Encoding == 'pca16':\n",
        "                f.write(\"PCA16 Encoding\\n\")\n",
        "            elif Encoding == 'autoencoder16':\n",
        "                f.write(\"autoencoder16 Encoding\\n\")\n",
        "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X3: \" + str(mean_X3) + \" standard deviation of X3: \" + str(stdev_X3))\n",
        "            f.write(\"\\n\")\n",
        "            f.write(\"mean of X4: \" + str(mean_X4) + \" standard deviation of X4: \" + str(stdev_X4))\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    f.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Result"
      ],
      "metadata": {
        "id": "AkoKAf4hLtkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This generates the results of the bechmarking code\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Here are possible combinations of benchmarking user could try.\n",
        "Unitaries: ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4', 'U_SU4', 'U_SU4_no_pooling', 'U_SU4_1D', 'U_9_1D']\n",
        "U_num_params: [2, 10, 10, 2, 6, 6, 4, 6, 15, 15, 15, 2]\n",
        "Encodings: ['resize256', 'pca8', 'autoencoder8', 'pca16-compact', 'autoencoder16-compact', 'pca32-1', 'autoencoder32-1',\n",
        "            'pca16-1', 'autoencoder16-1', 'pca30-1', 'autoencoder30-1', 'pca12-1', 'autoencoder12-1']\n",
        "dataset: 'mnist' or 'fashion_mnist'\n",
        "circuit: 'QCNN' or 'Hierarchical'\n",
        "cost_fn: 'mse' or 'cross_entropy'\n",
        "Note: when using 'mse' as cost_fn binary=\"True\" is recommended, when using 'cross_entropy' as cost_fn must be binary=\"False\".\n",
        "\"\"\"\n",
        "\n",
        "Unitaries = ['U_SU4', 'U_SU4_1D', 'U_SU4_no_pooling', 'U_9_1D']\n",
        "U_num_params = [15, 15, 15, 2]\n",
        "Encodings = ['resize256']\n",
        "dataset = 'fashion_mnist'\n",
        "classes = [0,1]\n",
        "binary = False\n",
        "cost_fn = 'cross_entropy'\n",
        "\n",
        "Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
        "#Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='Hierarchical', cost_fn=cost_fn, binary=binary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHd4OH8PLwve",
        "outputId": "3b09e90e-ed25-4bd2-ba26-61be46e04f04",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1732178173265,
          "user_tz": -360,
          "elapsed": 10544569,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4 resize256 with cross_entropy\n",
            "iteration:  0  cost:  17.488309311345876\n",
            "iteration:  10  cost:  17.305089371860788\n",
            "iteration:  20  cost:  17.019926370845482\n",
            "iteration:  30  cost:  17.14408181289371\n",
            "iteration:  40  cost:  17.062727199565597\n",
            "iteration:  50  cost:  17.476410560367004\n",
            "iteration:  60  cost:  17.50112511691655\n",
            "iteration:  70  cost:  17.222992376477674\n",
            "iteration:  80  cost:  16.867546761708557\n",
            "iteration:  90  cost:  17.750886917799367\n",
            "iteration:  100  cost:  17.38102563774101\n",
            "iteration:  110  cost:  17.176634737440956\n",
            "iteration:  120  cost:  17.07197908918767\n",
            "iteration:  130  cost:  18.34379632046924\n",
            "iteration:  140  cost:  16.603614718441904\n",
            "iteration:  150  cost:  17.572585887853634\n",
            "iteration:  160  cost:  17.29738115729915\n",
            "iteration:  170  cost:  17.453987555845682\n",
            "iteration:  180  cost:  17.183307672570393\n",
            "iteration:  190  cost:  17.184408905935957\n",
            "Accuracy for U_SU4 resize256 :0.4465\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4_1D resize256 with cross_entropy\n",
            "iteration:  0  cost:  17.74685550150907\n",
            "iteration:  10  cost:  16.855263007259406\n",
            "iteration:  20  cost:  17.558707744712315\n",
            "iteration:  30  cost:  17.634625849348275\n",
            "iteration:  40  cost:  17.379423197154072\n",
            "iteration:  50  cost:  18.179199885881896\n",
            "iteration:  60  cost:  18.369766749807553\n",
            "iteration:  70  cost:  17.39236184919759\n",
            "iteration:  80  cost:  17.86372633779226\n",
            "iteration:  90  cost:  19.521011307991827\n",
            "iteration:  100  cost:  18.265389791698205\n",
            "iteration:  110  cost:  18.446928200007203\n",
            "iteration:  120  cost:  17.90891663643722\n",
            "iteration:  130  cost:  17.987497425551943\n",
            "iteration:  140  cost:  16.408902614002198\n",
            "iteration:  150  cost:  17.48148542466867\n",
            "iteration:  160  cost:  16.49621720476305\n",
            "iteration:  170  cost:  18.813314859829283\n",
            "iteration:  180  cost:  19.118944818534786\n",
            "iteration:  190  cost:  18.902531694054595\n",
            "Accuracy for U_SU4_1D resize256 :0.496\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_SU4_no_pooling resize256 with cross_entropy\n",
            "iteration:  0  cost:  16.47669152350172\n",
            "iteration:  10  cost:  16.76587003195546\n",
            "iteration:  20  cost:  15.951420219711268\n",
            "iteration:  30  cost:  16.443017364639573\n",
            "iteration:  40  cost:  16.286956481285614\n",
            "iteration:  50  cost:  16.96910474569296\n",
            "iteration:  60  cost:  17.080775749729668\n",
            "iteration:  70  cost:  16.79417427693919\n",
            "iteration:  80  cost:  15.592324661617742\n",
            "iteration:  90  cost:  15.926930332896434\n",
            "iteration:  100  cost:  16.620314836899954\n",
            "iteration:  110  cost:  16.503422306282218\n",
            "iteration:  120  cost:  15.89931303411584\n",
            "iteration:  130  cost:  15.732330974948837\n",
            "iteration:  140  cost:  16.911829905228345\n",
            "iteration:  150  cost:  16.119702040010967\n",
            "iteration:  160  cost:  15.90092737856838\n",
            "iteration:  170  cost:  15.687143747793787\n",
            "iteration:  180  cost:  15.433417376725107\n",
            "iteration:  190  cost:  15.44019158949483\n",
            "Accuracy for U_SU4_no_pooling resize256 :0.5095\n",
            "\n",
            "\n",
            "Loss History for QCNN circuits, U_9_1D resize256 with cross_entropy\n",
            "iteration:  0  cost:  17.156690363953345\n",
            "iteration:  10  cost:  17.74055682639964\n",
            "iteration:  20  cost:  17.701086514354845\n",
            "iteration:  30  cost:  17.321026195866732\n",
            "iteration:  40  cost:  17.333104860303543\n",
            "iteration:  50  cost:  17.614755319800263\n",
            "iteration:  60  cost:  17.355255127702588\n",
            "iteration:  70  cost:  17.461321645113557\n",
            "iteration:  80  cost:  17.452982948242568\n",
            "iteration:  90  cost:  17.369431491975654\n",
            "iteration:  100  cost:  17.49152081984803\n",
            "iteration:  110  cost:  17.424307288117685\n",
            "iteration:  120  cost:  17.812059108712543\n",
            "iteration:  130  cost:  17.675580478299736\n",
            "iteration:  140  cost:  17.15382283611439\n",
            "iteration:  150  cost:  17.105454367825182\n",
            "iteration:  160  cost:  17.47097102629646\n",
            "iteration:  170  cost:  17.39076561577965\n",
            "iteration:  180  cost:  17.12665870900919\n",
            "iteration:  190  cost:  17.574015993404394\n",
            "Accuracy for U_9_1D resize256 :0.4295\n"
          ]
        }
      ]
    }
  ]
}