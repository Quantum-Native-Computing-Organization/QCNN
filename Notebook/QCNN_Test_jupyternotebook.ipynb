{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQdCeMkzRBDi"
   },
   "source": [
    "#Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InhiigcvRFHd",
    "outputId": "41bdaa71-fe68-44c4-f1d8-d6bbb08710f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane==0.35.1 (from -r requirements.txt (line 1))\n",
      "  Using cached PennyLane-0.35.1-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from -r requirements.txt (line 2)) (2.16.1)\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: medmnist==3.0.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from -r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from -r requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: autograd==1.6.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from -r requirements.txt (line 6)) (1.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: rustworkx in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.15.1)\n",
      "Requirement already satisfied: toml in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: semantic-version>=2.7 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: autoray>=0.6.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (5.5.0)\n",
      "Requirement already satisfied: pennylane-lightning>=0.35 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (0.39.0)\n",
      "Requirement already satisfied: requests in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pennylane==0.35.1->-r requirements.txt (line 1)) (4.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow==2.16.1->-r requirements.txt (line 2)) (2.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (4.67.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: fire in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.7.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from medmnist==3.0.1->-r requirements.txt (line 4)) (0.17.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from torch==2.2.2->-r requirements.txt (line 5)) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from torch==2.2.2->-r requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from torch==2.2.2->-r requirements.txt (line 5)) (2024.10.0)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from autograd==1.6.2->-r requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.6.0)\n",
      "INFO: pip is looking at multiple versions of pennylane-lightning to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pennylane-lightning>=0.35 (from pennylane==0.35.1->-r requirements.txt (line 1))\n",
      "  Using cached PennyLane_Lightning-0.38.0-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "  Using cached PennyLane_Lightning-0.37.0-cp312-cp312-win_amd64.whl.metadata (24 kB)\n",
      "  Using cached PennyLane_Lightning-0.36.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from requests->pennylane==0.35.1->-r requirements.txt (line 1)) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from pandas->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2.36.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (2024.9.20)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from scikit-image->medmnist==3.0.1->-r requirements.txt (line 4)) (0.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from sympy->torch==2.2.2->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tqdm->medmnist==3.0.1->-r requirements.txt (line 4)) (0.4.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.13.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shahr\\anaconda3\\envs\\notebook\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow==2.16.1->-r requirements.txt (line 2)) (0.1.2)\n",
      "Using cached PennyLane-0.35.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached PennyLane_Lightning-0.36.0-cp312-cp312-win_amd64.whl (5.6 MB)\n",
      "Installing collected packages: pennylane-lightning, pennylane\n",
      "  Attempting uninstall: pennylane-lightning\n",
      "    Found existing installation: PennyLane_Lightning 0.39.0\n",
      "    Uninstalling PennyLane_Lightning-0.39.0:\n",
      "      Successfully uninstalled PennyLane_Lightning-0.39.0\n",
      "  Attempting uninstall: pennylane\n",
      "    Found existing installation: PennyLane 0.39.0\n",
      "    Uninstalling PennyLane-0.39.0:\n",
      "      Successfully uninstalled PennyLane-0.39.0\n",
      "Successfully installed pennylane-0.35.1 pennylane-lightning-0.36.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNwOeT-nLj87"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "x6RCuHMpLjjV"
   },
   "outputs": [],
   "source": [
    "# Loads and Processes the data that will be used in QCNN and Hierarchical Classifier Training\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "pca32 = ['pca32-1', 'pca32-2', 'pca32-3', 'pca32-4']\n",
    "autoencoder32 = ['autoencoder32-1', 'autoencoder32-2', 'autoencoder32-3', 'autoencoder32-4']\n",
    "pca30 = ['pca30-1', 'pca30-2', 'pca30-3', 'pca30-4']\n",
    "autoencoder30 = ['autoencoder30-1', 'autoencoder30-2', 'autoencoder30-3', 'autoencoder30-4']\n",
    "pca16 = ['pca16-1', 'pca16-2', 'pca16-3', 'pca16-4', 'pca16-compact']\n",
    "autoencoder16 = ['autoencoder16-1', 'autoencoder16-2', 'autoencoder16-3', 'autoencoder16-4', 'autoencoder16-compact']\n",
    "pca12 = ['pca12-1', 'pca12-2', 'pca12-3', 'pca12-4']\n",
    "autoencoder12 = ['autoencoder12-1', 'autoencoder12-2', 'autoencoder12-3', 'autoencoder12-4']\n",
    "\n",
    "def data_load_and_process(dataset, classes=[0, 1], feature_reduction='resize256', binary=True):\n",
    "    if dataset == 'fashion_mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    elif dataset == 'mnist':\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    x_train, x_test = x_train[..., np.newaxis] / 255.0, x_test[..., np.newaxis] / 255.0  # normalize the data\n",
    "\n",
    "    if classes == 'odd_even':\n",
    "        odd = [1, 3, 5, 7, 9]\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y in odd else 0 for y in y_train]\n",
    "            Y_test = [1 if y in odd else 0 for y in y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y in odd else -1 for y in y_train]\n",
    "            Y_test = [1 if y in odd else -1 for y in y_test]\n",
    "\n",
    "    elif classes == '>4':\n",
    "        greater = [5, 6, 7, 8, 9]\n",
    "        X_train = x_train\n",
    "        X_test = x_test\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y in greater else 0 for y in y_train]\n",
    "            Y_test = [1 if y in greater else 0 for y in y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y in greater else -1 for y in y_train]\n",
    "            Y_test = [1 if y in greater else -1 for y in y_test]\n",
    "\n",
    "    else:\n",
    "        x_train_filter_01 = np.where((y_train == classes[0]) | (y_train == classes[1]))\n",
    "        x_test_filter_01 = np.where((y_test == classes[0]) | (y_test == classes[1]))\n",
    "\n",
    "        X_train, X_test = x_train[x_train_filter_01], x_test[x_test_filter_01]\n",
    "        Y_train, Y_test = y_train[x_train_filter_01], y_test[x_test_filter_01]\n",
    "\n",
    "        if binary == False:\n",
    "            Y_train = [1 if y == classes[0] else 0 for y in Y_train]\n",
    "            Y_test = [1 if y == classes[0] else 0 for y in Y_test]\n",
    "        elif binary == True:\n",
    "            Y_train = [1 if y == classes[0] else -1 for y in Y_train]\n",
    "            Y_test = [1 if y == classes[0] else -1 for y in Y_test]\n",
    "\n",
    "    if feature_reduction == 'resize256':\n",
    "        X_train = tf.image.resize(X_train[:], (256, 1)).numpy()\n",
    "        X_test = tf.image.resize(X_test[:], (256, 1)).numpy()\n",
    "        X_train, X_test = tf.squeeze(X_train).numpy(), tf.squeeze(X_test).numpy()\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    elif feature_reduction == 'pca8' or feature_reduction in pca32 \\\n",
    "            or feature_reduction in pca30 or feature_reduction in pca16 or feature_reduction in pca12:\n",
    "\n",
    "        X_train = tf.image.resize(X_train[:], (784, 1)).numpy()\n",
    "        X_test = tf.image.resize(X_test[:], (784, 1)).numpy()\n",
    "        X_train, X_test = tf.squeeze(X_train), tf.squeeze(X_test)\n",
    "\n",
    "        if feature_reduction == 'pca8':\n",
    "            pca = PCA(8)\n",
    "        elif feature_reduction in pca32:\n",
    "            pca = PCA(32)\n",
    "        elif feature_reduction in pca30:\n",
    "            pca = PCA(30)\n",
    "        elif feature_reduction in pca16:\n",
    "            pca = PCA(16)\n",
    "        elif feature_reduction in pca12:\n",
    "            pca = PCA(12)\n",
    "\n",
    "\n",
    "        X_train = pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "\n",
    "        # Rescale for angle embedding\n",
    "        if feature_reduction == 'pca8' or feature_reduction == 'pca16-compact' or \\\n",
    "                feature_reduction in pca30 or feature_reduction in pca12:\n",
    "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())),\\\n",
    "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "    elif feature_reduction == 'autoencoder8' or feature_reduction in autoencoder32 \\\n",
    "            or feature_reduction in autoencoder30 or feature_reduction in autoencoder16 or feature_reduction in autoencoder12:\n",
    "        if feature_reduction == 'autoencoder8':\n",
    "            latent_dim = 8\n",
    "        elif feature_reduction in autoencoder32:\n",
    "            latent_dim = 32\n",
    "        elif feature_reduction in autoencoder30:\n",
    "            latent_dim = 30\n",
    "        elif feature_reduction in autoencoder16:\n",
    "            latent_dim = 16\n",
    "        elif feature_reduction in autoencoder12:\n",
    "            latent_dim = 12\n",
    "\n",
    "\n",
    "\n",
    "        class Autoencoder(Model):\n",
    "            def __init__(self, latent_dim):\n",
    "                super(Autoencoder, self).__init__()\n",
    "                self.latent_dim = latent_dim\n",
    "                self.encoder = tf.keras.Sequential([\n",
    "                    layers.Flatten(),\n",
    "                    layers.Dense(latent_dim, activation='relu'),\n",
    "                ])\n",
    "                self.decoder = tf.keras.Sequential([\n",
    "                    layers.Dense(784, activation='sigmoid'),\n",
    "                    layers.Reshape((28, 28))\n",
    "                ])\n",
    "\n",
    "            def call(self, x):\n",
    "                encoded = self.encoder(x)\n",
    "                decoded = self.decoder(encoded)\n",
    "                return decoded\n",
    "\n",
    "        autoencoder = Autoencoder(latent_dim)\n",
    "\n",
    "        autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "        autoencoder.fit(X_train, X_train,\n",
    "                        epochs=10,\n",
    "                        shuffle=True,\n",
    "                        validation_data=(X_test, X_test))\n",
    "\n",
    "        X_train, X_test = autoencoder.encoder(X_train).numpy(), autoencoder.encoder(X_test).numpy()\n",
    "\n",
    "        # Rescale for Angle Embedding\n",
    "        # Note this is not a rigorous rescaling method\n",
    "        if feature_reduction == 'autoencoder8' or feature_reduction == 'autoencoder16-compact' or\\\n",
    "                feature_reduction in autoencoder30 or feature_reduction in autoencoder12:\n",
    "            X_train, X_test = (X_train - X_train.min()) * (np.pi / (X_train.max() - X_train.min())), \\\n",
    "                              (X_test - X_test.min()) * (np.pi / (X_test.max() - X_test.min()))\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "039T2w4iSRab"
   },
   "source": [
    "#Angular_hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e8bQcfcXSW05"
   },
   "outputs": [],
   "source": [
    "# This is an implementation of an alternative Mottonen State Preparation to avoid normalization problem.\n",
    "import pennylane as qml\n",
    "\n",
    "# 3 bits of information is embedded in 2 wires\n",
    "def Angular_Hybrid_2(X, wires):\n",
    "    qml.RY(X[0], wires=wires[0])\n",
    "\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
    "\n",
    "# 15 bits of information is embedded in 4 wires\n",
    "def Angular_Hybrid_4(X, wires):\n",
    "    qml.RY(X[0], wires=wires[0])\n",
    "\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[1], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRY(X[2], wires=[wires[0], wires[1]])\n",
    "\n",
    "    qml.RY(X[3], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[4], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "    qml.RY(X[5], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[1], wires[2]])\n",
    "    qml.RY(X[6], wires=wires[2])\n",
    "    qml.CNOT(wires=[wires[0], wires[2]])\n",
    "\n",
    "    qml.RY(X[7], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[8], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[9], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[10], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])\n",
    "    qml.RY(X[11], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[12], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[1], wires[3]])\n",
    "    qml.RY(X[13], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[2], wires[3]])\n",
    "    qml.RY(X[14], wires=wires[3])\n",
    "    qml.CNOT(wires=[wires[0], wires[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Yg25yMmQjAb"
   },
   "source": [
    "#Unitary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-9qnNHIOQnps"
   },
   "outputs": [],
   "source": [
    "# This module contains the set of unitary ansatze that will be used to benchmark the performances of Quantum Convolutional Neural Network (QCNN) in QCNN.ipynb module\n",
    "import pennylane as qml\n",
    "\n",
    "# Unitary Ansatze for Convolutional Layer\n",
    "def U_TTN(params, wires):  # 2 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_5(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRZ(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_6(params, wires):  # 10 params\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "    qml.RZ(params[2], wires=wires[0])\n",
    "    qml.RZ(params[3], wires=wires[1])\n",
    "    qml.CRX(params[4], wires=[wires[1], wires[0]])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[6], wires=wires[0])\n",
    "    qml.RX(params[7], wires=wires[1])\n",
    "    qml.RZ(params[8], wires=wires[0])\n",
    "    qml.RZ(params[9], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_9(params, wires):  # 2 params\n",
    "    qml.Hadamard(wires=wires[0])\n",
    "    qml.Hadamard(wires=wires[1])\n",
    "    qml.CZ(wires=[wires[0], wires[1]])\n",
    "    qml.RX(params[0], wires=wires[0])\n",
    "    qml.RX(params[1], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_13(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRZ(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRZ(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_14(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CRX(params[2], wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[3], wires=wires[0])\n",
    "    qml.RY(params[4], wires=wires[1])\n",
    "    qml.CRX(params[5], wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_15(params, wires):  # 4 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "\n",
    "\n",
    "def U_SO4(params, wires):  # 6 params\n",
    "    qml.RY(params[0], wires=wires[0])\n",
    "    qml.RY(params[1], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[2], wires=wires[0])\n",
    "    qml.RY(params[3], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[4], wires=wires[0])\n",
    "    qml.RY(params[5], wires=wires[1])\n",
    "\n",
    "\n",
    "def U_SU4(params, wires): # 15 params\n",
    "    qml.U3(params[0], params[1], params[2], wires=wires[0])\n",
    "    qml.U3(params[3], params[4], params[5], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.RY(params[6], wires=wires[0])\n",
    "    qml.RZ(params[7], wires=wires[1])\n",
    "    qml.CNOT(wires=[wires[1], wires[0]])\n",
    "    qml.RY(params[8], wires=wires[0])\n",
    "    qml.CNOT(wires=[wires[0], wires[1]])\n",
    "    qml.U3(params[9], params[10], params[11], wires=wires[0])\n",
    "    qml.U3(params[12], params[13], params[14], wires=wires[1])\n",
    "\n",
    "# Pooling Layer\n",
    "\n",
    "def Pooling_ansatz1(params, wires): #2 params\n",
    "    qml.CRZ(params[0], wires=[wires[0], wires[1]])\n",
    "    qml.PauliX(wires=wires[0])\n",
    "    qml.CRX(params[1], wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz2(wires): #0 params\n",
    "    qml.CRZ(wires=[wires[0], wires[1]])\n",
    "\n",
    "def Pooling_ansatz3(*params, wires): #3 params\n",
    "    qml.CRot(*params, wires=[wires[0], wires[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MULojT0GQlAZ"
   },
   "source": [
    "#Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "37FbHsvrQwtN"
   },
   "outputs": [],
   "source": [
    "# This is an implementation of data_embedding function used for 8 qubits Quantum Convolutional Neural Network (QCNN)\n",
    "# and Hierarchical Quantum Classifier circuit.\n",
    "import pennylane as qml\n",
    "from pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\n",
    "from pennylane.templates.state_preparations import MottonenStatePreparation\n",
    "import numpy as np\n",
    "\n",
    "def data_embedding(X, embedding_type='Amplitude'):\n",
    "    if embedding_type == 'Amplitude':\n",
    "        AmplitudeEmbedding(X, wires=range(8), normalize=True)\n",
    "    elif embedding_type == 'Angle':\n",
    "        AngleEmbedding(X, wires=range(8), rotation='Y')\n",
    "    elif embedding_type == 'Angle-compact':\n",
    "        AngleEmbedding(X[:8], wires=range(8), rotation='X')\n",
    "        AngleEmbedding(X[8:16], wires=range(8), rotation='Y')\n",
    "\n",
    "    # Hybrid Direct Embedding (HDE)\n",
    "    elif embedding_type == 'Amplitude-Hybrid4-1' or embedding_type == 'Amplitude-Hybrid4-2' or \\\n",
    "            embedding_type == 'Amplitude-Hybrid4-3' or embedding_type == 'Amplitude-Hybrid4-4':\n",
    "        X1 = X[:2 ** 4]\n",
    "        X2 = X[2 ** 4:2 ** 5]\n",
    "        norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
    "        X1, X2 = X1 / norm_X1, X2 / norm_X2\n",
    "\n",
    "        if embedding_type == 'Amplitude-Hybrid4-1':\n",
    "            MottonenStatePreparation(X1, wires=[0, 1, 2, 3])\n",
    "            MottonenStatePreparation(X2, wires=[4, 5, 6, 7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-2':\n",
    "            MottonenStatePreparation(X1, wires=[0, 2, 4, 6])\n",
    "            MottonenStatePreparation(X2, wires=[1, 3, 5, 7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-3':\n",
    "            MottonenStatePreparation(X1, wires=[0, 1, 6, 7])\n",
    "            MottonenStatePreparation(X2, wires=[2, 3, 4, 5])\n",
    "        elif embedding_type == 'Amplitude-Hybrid4-4':\n",
    "            MottonenStatePreparation(X1, wires=[0, 3, 4, 7])\n",
    "            MottonenStatePreparation(X2, wires=[1, 2, 5, 6])\n",
    "\n",
    "    elif embedding_type == 'Amplitude-Hybrid2-1' or embedding_type == 'Amplitude-Hybrid2-2' \\\n",
    "            or embedding_type == 'Amplitude-Hybrid2-3' or embedding_type == 'Amplitude-Hybrid2-4':\n",
    "        X1 = X[:4]\n",
    "        X2 = X[4:8]\n",
    "        X3 = X[8:12]\n",
    "        X4 = X[12:16]\n",
    "        norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(X3), np.linalg.norm(\n",
    "            X4)\n",
    "        X1, X2, X3, X4 = X1 / norm_X1, X2 / norm_X2, X3 / norm_X3, X4 / norm_X4\n",
    "\n",
    "        if embedding_type == 'Amplitude-Hybrid2-1':\n",
    "            MottonenStatePreparation(X1, wires=[0,1])\n",
    "            MottonenStatePreparation(X2, wires=[2,3])\n",
    "            MottonenStatePreparation(X3, wires=[4,5])\n",
    "            MottonenStatePreparation(X4, wires=[6,7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-2':\n",
    "            MottonenStatePreparation(X1, wires=[0,4])\n",
    "            MottonenStatePreparation(X2, wires=[1,5])\n",
    "            MottonenStatePreparation(X3, wires=[2,6])\n",
    "            MottonenStatePreparation(X4, wires=[3,7])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-3':\n",
    "            MottonenStatePreparation(X1, wires=[0,7])\n",
    "            MottonenStatePreparation(X2, wires=[1,6])\n",
    "            MottonenStatePreparation(X3, wires=[2,5])\n",
    "            MottonenStatePreparation(X4, wires=[3,4])\n",
    "        elif embedding_type == 'Amplitude-Hybrid2-4':\n",
    "            MottonenStatePreparation(X1, wires=[0,2])\n",
    "            MottonenStatePreparation(X2, wires=[1,3])\n",
    "            MottonenStatePreparation(X3, wires=[4,6])\n",
    "            MottonenStatePreparation(X4, wires=[5,7])\n",
    "\n",
    "    # Hybrid Angle Embedding (HAE)\n",
    "    elif embedding_type == 'Angular-Hybrid4-1' or embedding_type == 'Angular-Hybrid4-2' or \\\n",
    "            embedding_type == 'Angular-Hybrid4-3' or embedding_type == 'Angular-Hybrid4-4':\n",
    "        N = 15 # 15 classical data in 4 qubits\n",
    "        X1 = X[:N]\n",
    "        X2 = X[N:2*N]\n",
    "\n",
    "        if embedding_type == 'Angular-Hybrid4-1':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 1, 2, 3])\n",
    "            Angular_Hybrid_4(X2, wires=[4, 5, 6, 7])\n",
    "        elif embedding_type == 'Angular-Hybrid4-2':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 2, 4, 6])\n",
    "            Angular_Hybrid_4(X2, wires=[1, 3, 5, 7])\n",
    "        elif embedding_type == 'Angular-Hybrid4-3':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 1, 6, 7])\n",
    "            Angular_Hybrid_4(X2, wires=[2, 3, 4, 5])\n",
    "        elif embedding_type == 'Angular-Hybrid4-4':\n",
    "            Angular_Hybrid_4(X1, wires=[0, 3, 4, 7])\n",
    "            Angular_Hybrid_4(X2, wires=[1, 2, 5, 6])\n",
    "\n",
    "    elif embedding_type == 'Angular-Hybrid2-1' or embedding_type == 'Angular-Hybrid2-2' \\\n",
    "            or embedding_type == 'Angular-Hybrid2-3' or embedding_type == 'Angular-Hybrid2-4':\n",
    "        N = 3  # 3 classical bits in 2 qubits\n",
    "        X1 = X[:N]\n",
    "        X2 = X[N:2*N]\n",
    "        X3 = X[2*N:3*N]\n",
    "        X4 = X[3*N:4*N]\n",
    "\n",
    "        if embedding_type == 'Angular-Hybrid2-1':\n",
    "            Angular_Hybrid_2(X1, wires=[0,1])\n",
    "            Angular_Hybrid_2(X2, wires=[2,3])\n",
    "            Angular_Hybrid_2(X3, wires=[4,5])\n",
    "            Angular_Hybrid_2(X4, wires=[6,7])\n",
    "        elif embedding_type == 'Angular-Hybrid2-2':\n",
    "            Angular_Hybrid_2(X1, wires=[0,4])\n",
    "            Angular_Hybrid_2(X2, wires=[1,5])\n",
    "            Angular_Hybrid_2(X3, wires=[2,6])\n",
    "            Angular_Hybrid_2(X4, wires=[3,7])\n",
    "        elif embedding_type == 'Angular-Hybrid2-3':\n",
    "            Angular_Hybrid_2(X1, wires=[0,7])\n",
    "            Angular_Hybrid_2(X2, wires=[1,6])\n",
    "            Angular_Hybrid_2(X3, wires=[2,5])\n",
    "            Angular_Hybrid_2(X4, wires=[3,4])\n",
    "        elif embedding_type == 'Angular-Hybrid2-4':\n",
    "            Angular_Hybrid_2(X1, wires=[0,2])\n",
    "            Angular_Hybrid_2(X2, wires=[1,3])\n",
    "            Angular_Hybrid_2(X3, wires=[4,6])\n",
    "            Angular_Hybrid_2(X4, wires=[5,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ao0qIpOENFZ0"
   },
   "source": [
    "#QCNN Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ywqqn0KbNf80"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "\n",
    "# Quantum Circuits for Convolutional layers\n",
    "def conv_layer1(U, params):\n",
    "    U(params, wires=[0, 7])\n",
    "    for i in range(0, 8, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "    for i in range(1, 7, 2):\n",
    "        U(params, wires=[i, i + 1])\n",
    "def conv_layer2(U, params):\n",
    "    U(params, wires=[0, 6])\n",
    "    U(params, wires=[0, 2])\n",
    "    U(params, wires=[4, 6])\n",
    "    U(params, wires=[2, 4])\n",
    "def conv_layer3(U, params):\n",
    "    U(params, wires=[0,4])\n",
    "\n",
    "# Quantum Circuits for Pooling layers\n",
    "def pooling_layer1(V, params):\n",
    "    for i in range(0, 8, 2):\n",
    "        V(params, wires=[i + 1, i])\n",
    "def pooling_layer2(V, params):\n",
    "    V(params, wires=[2,0])\n",
    "    V(params, wires=[6,4])\n",
    "def pooling_layer3(V, params):\n",
    "    V(params, wires=[0,4])\n",
    "\n",
    "\n",
    "\n",
    "def QCNN_structure(U, params, U_params):\n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params: 2 * U_params]\n",
    "    param3 = params[2 * U_params: 3 * U_params]\n",
    "    param4 = params[3 * U_params: 3 * U_params + 2]\n",
    "    param5 = params[3 * U_params + 2: 3 * U_params + 4]\n",
    "    param6 = params[3 * U_params + 4: 3 * U_params + 6]\n",
    "\n",
    "    # Pooling Ansatz1 is used by default\n",
    "    conv_layer1(U, param1)\n",
    "    pooling_layer1(Pooling_ansatz1, param4)\n",
    "    conv_layer2(U, param2)\n",
    "    pooling_layer2(Pooling_ansatz1, param5)\n",
    "    conv_layer3(U, param3)\n",
    "    pooling_layer3(Pooling_ansatz1, param6)\n",
    "\n",
    "\n",
    "def QCNN_structure_without_pooling(U, params, U_params):\n",
    "    param1 = params[0:U_params]\n",
    "    param2 = params[U_params: 2 * U_params]\n",
    "    param3 = params[2 * U_params: 3 * U_params]\n",
    "\n",
    "    conv_layer1(U, param1)\n",
    "    conv_layer2(U, param2)\n",
    "    conv_layer3(U, param3)\n",
    "\n",
    "def QCNN_1D_circuit(U, params, U_params):\n",
    "    param1 = params[0: U_params]\n",
    "    param2 = params[U_params: 2*U_params]\n",
    "    param3 = params[2*U_params: 3*U_params]\n",
    "\n",
    "    for i in range(0, 8, 2):\n",
    "        U(param1, wires=[i, i + 1])\n",
    "    for i in range(1, 7, 2):\n",
    "        U(param1, wires=[i, i + 1])\n",
    "\n",
    "    U(param2, wires=[2,3])\n",
    "    U(param2, wires=[4,5])\n",
    "    U(param3, wires=[3,4])\n",
    "\n",
    "\n",
    "\n",
    "dev = qml.device('default.qubit', wires = 8)\n",
    "@qml.qnode(dev)\n",
    "def QCNN(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
    "\n",
    "\n",
    "    # Data Embedding\n",
    "    data_embedding(X, embedding_type=embedding_type)\n",
    "\n",
    "    # Quantum Convolutional Neural Network\n",
    "    if U == 'U_TTN':\n",
    "        QCNN_structure(U_TTN, params, U_params)\n",
    "    elif U == 'U_5':\n",
    "        QCNN_structure(U_5, params, U_params)\n",
    "    elif U == 'U_6':\n",
    "        QCNN_structure(U_6, params, U_params)\n",
    "    elif U == 'U_9':\n",
    "        QCNN_structure(U_9, params, U_params)\n",
    "    elif U == 'U_13':\n",
    "        QCNN_structure(U_13, params, U_params)\n",
    "    elif U == 'U_14':\n",
    "        QCNN_structure(U_14, params, U_params)\n",
    "    elif U == 'U_15':\n",
    "        QCNN_structure(U_15, params, U_params)\n",
    "    elif U == 'U_SO4':\n",
    "        QCNN_structure(unitary.U_SO4, params, U_params)\n",
    "    elif U == 'U_SU4':\n",
    "        QCNN_structure(U_SU4, params, U_params)\n",
    "    elif U == 'U_SU4_no_pooling':\n",
    "        QCNN_structure_without_pooling(U_SU4, params, U_params)\n",
    "    elif U == 'U_SU4_1D':\n",
    "        QCNN_1D_circuit(U_SU4, params, U_params)\n",
    "    elif U == 'U_9_1D':\n",
    "        QCNN_1D_circuit(U_9, params, U_params)\n",
    "    else:\n",
    "        print(\"Invalid Unitary Ansatze\")\n",
    "        return False\n",
    "\n",
    "    if cost_fn == 'mse':\n",
    "        result = qml.expval(qml.PauliZ(4))\n",
    "    elif cost_fn == 'cross_entropy':\n",
    "        result = qml.probs(wires=4)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2I6ICMKNIG5"
   },
   "source": [
    "#Hierarchical Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "73fa3h4JNkmX"
   },
   "outputs": [],
   "source": [
    "# Implementaion of Hierarchical Quantum Classifier Structure.\n",
    "import pennylane as qml\n",
    "\n",
    "\n",
    "dev_TTN = qml.device('default.qubit', wires=8)\n",
    "\n",
    "def Hierarchical_structure(U, params, U_params):\n",
    "    param1 = params[0 * U_params:1 * U_params]\n",
    "    param2 = params[1 * U_params:2 * U_params]\n",
    "    param3 = params[2 * U_params:3 * U_params]\n",
    "    param4 = params[3 * U_params:4 * U_params]\n",
    "    param5 = params[4 * U_params:5 * U_params]\n",
    "    param6 = params[5 * U_params:6 * U_params]\n",
    "    param7 = params[6 * U_params:7 * U_params]\n",
    "\n",
    "    # 1st Layer\n",
    "    U(param1, wires=[0, 1])\n",
    "    U(param2, wires=[2, 3])\n",
    "    U(param3, wires=[4, 5])\n",
    "    U(param4, wires=[6, 7])\n",
    "    # 2nd Layer\n",
    "    U(param5, wires=[1, 3])\n",
    "    U(param6, wires=[5, 7])\n",
    "    # 3rd Layer\n",
    "    U(param7, wires=[3, 7])\n",
    "\n",
    "\n",
    "\n",
    "@qml.qnode(dev_TTN)\n",
    "def Hierarchical_classifier(X, params, U, U_params, embedding_type='Amplitude', cost_fn='cross_entropy'):\n",
    "    data_embedding(X, embedding_type=embedding_type)\n",
    "    if U == 'U_TTN':\n",
    "        Hierarchical_structure(U_TTN, params, U_params)\n",
    "    elif U == 'U_5':\n",
    "        Hierarchical_structure(U_5, params, U_params)\n",
    "    elif U == 'U_6':\n",
    "        Hierarchical_structure(U_6, params, U_params)\n",
    "    elif U == 'U_9':\n",
    "        Hierarchical_structure(U_9, params, U_params)\n",
    "    elif U == 'U_13':\n",
    "        Hierarchical_structure(U_13, params, U_params)\n",
    "    elif U == 'U_14':\n",
    "        Hierarchical_structure(U_14, params, U_params)\n",
    "    elif U == 'U_15':\n",
    "        Hierarchical_structure(U_15, params, U_params)\n",
    "    elif U == 'U_SO4':\n",
    "        Hierarchical_structure(U_SO4, params, U_params)\n",
    "    elif U == 'U_SU4':\n",
    "        Hierarchical_structure(U_SU4, params, U_params)\n",
    "    else:\n",
    "        print(\"Invalid Unitary Ansatz\")\n",
    "        return False\n",
    "    if cost_fn == 'mse':\n",
    "        result = qml.expval(qml.PauliZ(7))\n",
    "    elif cost_fn == 'cross_entropy':\n",
    "        result = qml.probs(wires=7)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh9YDNmfLVL-"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dbsaTU7ELVwq"
   },
   "outputs": [],
   "source": [
    "# Implementation of Quantum circuit training procedure\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import autograd.numpy as anp\n",
    "import torch\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss = loss + (l - p) ** 2\n",
    "    loss = loss / len(labels)\n",
    "    return loss\n",
    "\n",
    "def cross_entropy(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        c_entropy = l * (anp.log(p[l])) + (1 - l) * anp.log(1 - p[1 - l])\n",
    "        loss = loss + c_entropy\n",
    "    return -1 * loss\n",
    "\n",
    "def cost(params, X, Y, U, U_params, embedding_type, circuit, cost_fn):\n",
    "    if circuit == 'QCNN':\n",
    "        predictions = [QCNN(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
    "    elif circuit == 'Hierarchical':\n",
    "        predictions = [Hierarchical_classifier(x, params, U, U_params, embedding_type, cost_fn=cost_fn) for x in X]\n",
    "\n",
    "    if cost_fn == 'mse':\n",
    "        loss = square_loss(Y, predictions)\n",
    "    elif cost_fn == 'cross_entropy':\n",
    "        loss = cross_entropy(Y, predictions)\n",
    "    return loss\n",
    "\n",
    "# Circuit training parameters\n",
    "steps = 200\n",
    "learning_rate = 0.01\n",
    "batch_size = 25\n",
    "def circuit_training(X_train, Y_train, U, U_params, embedding_type, circuit, cost_fn):\n",
    "    if circuit == 'QCNN':\n",
    "        if U == 'U_SU4_no_pooling' or U == 'U_SU4_1D' or U == 'U_9_1D':\n",
    "            total_params = U_params * 3\n",
    "        else:\n",
    "            total_params = U_params * 3 + 2 * 3\n",
    "    elif circuit == 'Hierarchical':\n",
    "        total_params = U_params * 7\n",
    "\n",
    "    #params = np.random.randn(total_params, requires_grad=True)\n",
    "    #params = tf.Variable(tf.random.normal(shape=(total_params,)), trainable=True)#works\n",
    "    params = tf.Variable(tf.random.normal([total_params]), dtype=tf.float32) #works\n",
    "    opt = qml.NesterovMomentumOptimizer(stepsize=learning_rate)\n",
    "    loss_history = []\n",
    "\n",
    "    for it in range(steps):\n",
    "        batch_index = np.random.randint(0, len(X_train), (batch_size,))\n",
    "        X_batch = [X_train[i] for i in batch_index]\n",
    "        Y_batch = [Y_train[i] for i in batch_index]\n",
    "        params, cost_new = opt.step_and_cost(lambda v: cost(v, X_batch, Y_batch, U, U_params, embedding_type, circuit, cost_fn),\n",
    "                                                     params)\n",
    "        loss_history.append(cost_new)\n",
    "        if it % 10 == 0:\n",
    "            print(\"iteration: \", it, \" cost: \", cost_new)\n",
    "    return loss_history, params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmMk8E8PLDfb"
   },
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xczHohbTLB-c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy_test(predictions, labels, cost_fn, binary = True):\n",
    "    if cost_fn == 'mse':\n",
    "        if binary == True:\n",
    "            acc = 0\n",
    "            for l, p in zip(labels, predictions):\n",
    "                if np.abs(l - p) < 1:\n",
    "                    acc = acc + 1\n",
    "            return acc / len(labels)\n",
    "\n",
    "        else:\n",
    "            acc = 0\n",
    "            for l, p in zip(labels, predictions):\n",
    "                if np.abs(l - p) < 0.5:\n",
    "                    acc = acc + 1\n",
    "            return acc / len(labels)\n",
    "\n",
    "    elif cost_fn == 'cross_entropy':\n",
    "        acc = 0\n",
    "        for l,p in zip(labels, predictions):\n",
    "            if p[0] > p[1]:\n",
    "                P = 0\n",
    "            else:\n",
    "                P = 1\n",
    "            if P == l:\n",
    "                acc = acc + 1\n",
    "        return acc / len(labels)\n",
    "\n",
    "\n",
    "def Encoding_to_Embedding(Encoding):\n",
    "    # Amplitude Embedding / Angle Embedding\n",
    "    if Encoding == 'resize256':\n",
    "        Embedding = 'Amplitude'\n",
    "    elif Encoding == 'pca8':\n",
    "        Embedding = 'Angle'\n",
    "    elif Encoding == 'autoencoder8':\n",
    "        Embedding = 'Angle'\n",
    "\n",
    "    # Amplitude Hybrid Embedding\n",
    "    # 4 qubit block\n",
    "    elif Encoding == 'pca32-1':\n",
    "        Embedding = 'Amplitude-Hybrid4-1'\n",
    "    elif Encoding == 'autoencoder32-1':\n",
    "        Embedding = 'Amplitude-Hybrid4-1'\n",
    "\n",
    "    elif Encoding == 'pca32-2':\n",
    "        Embedding = 'Amplitude-Hybrid4-2'\n",
    "    elif Encoding == 'autoencoder32-2':\n",
    "        Embedding = 'Amplitude-Hybrid4-2'\n",
    "\n",
    "    elif Encoding == 'pca32-3':\n",
    "        Embedding = 'Amplitude-Hybrid4-3'\n",
    "    elif Encoding == 'autoencoder32-3':\n",
    "        Embedding = 'Amplitude-Hybrid4-3'\n",
    "\n",
    "    elif Encoding == 'pca32-4':\n",
    "        Embedding = 'Amplitude-Hybrid4-4'\n",
    "    elif Encoding == 'autoencoder32-4':\n",
    "        Embedding = 'Amplitude-Hybrid4-4'\n",
    "\n",
    "    # 2 qubit block\n",
    "    elif Encoding == 'pca16-1':\n",
    "        Embedding = 'Amplitude-Hybrid2-1'\n",
    "    elif Encoding == 'autoencoder16-1':\n",
    "        Embedding = 'Amplitude-Hybrid2-1'\n",
    "\n",
    "    elif Encoding == 'pca16-2':\n",
    "        Embedding = 'Amplitude-Hybrid2-2'\n",
    "    elif Encoding == 'autoencoder16-2':\n",
    "        Embedding = 'Amplitude-Hybrid2-2'\n",
    "\n",
    "    elif Encoding == 'pca16-3':\n",
    "        Embedding = 'Amplitude-Hybrid2-3'\n",
    "    elif Encoding == 'autoencoder16-3':\n",
    "        Embedding = 'Amplitude-Hybrid2-3'\n",
    "\n",
    "    elif Encoding == 'pca16-4':\n",
    "        Embedding = 'Amplitude-Hybrid2-4'\n",
    "    elif Encoding == 'autoencoder16-4':\n",
    "        Embedding = 'Amplitude-Hybrid2-4'\n",
    "\n",
    "    # Angular HybridEmbedding\n",
    "    # 4 qubit block\n",
    "    elif Encoding == 'pca30-1':\n",
    "        Embedding = 'Angular-Hybrid4-1'\n",
    "    elif Encoding == 'autoencoder30-1':\n",
    "        Embedding = 'Angular-Hybrid4-1'\n",
    "\n",
    "    elif Encoding == 'pca30-2':\n",
    "        Embedding = 'Angular-Hybrid4-2'\n",
    "    elif Encoding == 'autoencoder30-2':\n",
    "        Embedding = 'Angular-Hybrid4-2'\n",
    "\n",
    "    elif Encoding == 'pca30-3':\n",
    "        Embedding = 'Angular-Hybrid4-3'\n",
    "    elif Encoding == 'autoencoder30-3':\n",
    "        Embedding = 'Angular-Hybrid4-3'\n",
    "\n",
    "    elif Encoding == 'pca30-4':\n",
    "        Embedding = 'Angular-Hybrid4-4'\n",
    "    elif Encoding == 'autoencoder30-4':\n",
    "        Embedding = 'Angular-Hybrid4-4'\n",
    "\n",
    "    # 2 qubit block\n",
    "    elif Encoding == 'pca12-1':\n",
    "        Embedding = 'Angular-Hybrid2-1'\n",
    "    elif Encoding == 'autoencoder12-1':\n",
    "        Embedding = 'Angular-Hybrid2-1'\n",
    "\n",
    "    elif Encoding == 'pca12-2':\n",
    "        Embedding = 'Angular-Hybrid2-2'\n",
    "    elif Encoding == 'autoencoder12-2':\n",
    "        Embedding = 'Angular-Hybrid2-2'\n",
    "\n",
    "    elif Encoding == 'pca12-3':\n",
    "        Embedding = 'Angular-Hybrid2-3'\n",
    "    elif Encoding == 'autoencoder12-3':\n",
    "        Embedding = 'Angular-Hybrid2-3'\n",
    "\n",
    "    elif Encoding == 'pca12-4':\n",
    "        Embedding = 'Angular-Hybrid2-4'\n",
    "    elif Encoding == 'autoencoder12-4':\n",
    "        Embedding = 'Angular-Hybrid2-4'\n",
    "\n",
    "    # Two Gates Compact Encoding\n",
    "    elif Encoding == 'pca16-compact':\n",
    "        Embedding = 'Angle-compact'\n",
    "    elif Encoding == 'autoencoder16-compact':\n",
    "        Embedding = 'Angle-compact'\n",
    "    return Embedding\n",
    "\n",
    "\n",
    "def Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit, cost_fn, binary=True):\n",
    "    I = len(Unitaries)\n",
    "    J = len(Encodings)\n",
    "\n",
    "    for i in range(I):\n",
    "        for j in range(J):\n",
    "            f = open('Result/result.txt', 'a')\n",
    "            U = Unitaries[i]\n",
    "            U_params = U_num_params[i]\n",
    "            Encoding = Encodings[j]\n",
    "            Embedding = Encoding_to_Embedding(Encoding)\n",
    "\n",
    "            X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
    "                                                                          feature_reduction=Encoding, binary=binary)\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
    "            loss_history, trained_params = circuit_training(X_train, Y_train, U, U_params, Embedding, circuit, cost_fn)\n",
    "\n",
    "            if circuit == 'QCNN':\n",
    "                predictions = [QCNN(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
    "            elif circuit == 'Hierarchical':\n",
    "                predictions = [Hierarchical_classifier(x, trained_params, U, U_params, Embedding, cost_fn) for x in X_test]\n",
    "\n",
    "            accuracy = accuracy_test(predictions, Y_test, cost_fn, binary)\n",
    "            print(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
    "\n",
    "            f.write(\"Loss History for \" + circuit + \" circuits, \" + U + \" \" + Encoding + \" with \" + cost_fn)\n",
    "            f.write(\"\\n\")\n",
    "            f.write(str(loss_history))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"Accuracy for \" + U + \" \" + Encoding + \" :\" + str(accuracy))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    f.close()\n",
    "\n",
    "def Data_norm(dataset, classes, Encodings, binary=True):\n",
    "    J = len(Encodings)\n",
    "    Num_data = 10000\n",
    "\n",
    "    f = open('Result/data_norm.txt', 'a')\n",
    "\n",
    "    for j in range(J):\n",
    "        Encoding = Encodings[j]\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test = data_load_and_process(dataset, classes=classes,\n",
    "                                                                          feature_reduction=Encoding, binary=binary)\n",
    "\n",
    "        if Encoding == 'pca32-3' or Encoding == 'autoencoder32-3':\n",
    "            norms_X1 = []\n",
    "            norms_X2 = []\n",
    "            for i in range(Num_data):\n",
    "                index = np.random.randint(0, len(X_train))\n",
    "                X = X_train[index]\n",
    "\n",
    "                X1 = X[:2 ** 4]\n",
    "                X2 = X[2 ** 4:2 ** 5]\n",
    "                norm_X1, norm_X2 = np.linalg.norm(X1), np.linalg.norm(X2)\n",
    "                norms_X1.append(norm_X1)\n",
    "                norms_X2.append(norm_X2)\n",
    "\n",
    "            norms_X1, norms_X2 = np.array(norms_X1), np.array(norms_X2)\n",
    "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
    "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
    "\n",
    "            if Encoding == 'pca32-3':\n",
    "                f.write(\"PCA32 Encoding\\n\")\n",
    "            elif Encoding == 'autoencoder32-3':\n",
    "                f.write(\"autoencoder32 Encoding\\n\")\n",
    "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        elif Encoding == 'pca16' or Encoding == 'autoencoder16':\n",
    "            norms_X1 = []\n",
    "            norms_X2 = []\n",
    "            norms_X3 = []\n",
    "            norms_X4 = []\n",
    "            for i in range(Num_data):\n",
    "                index = np.random.randint(0, len(X_train))\n",
    "                X = X_train[index]\n",
    "\n",
    "                X1 = X[:4]\n",
    "                X2 = X[4:8]\n",
    "                X3 = X[8:12]\n",
    "                X4 = X[12:16]\n",
    "                norm_X1, norm_X2, norm_X3, norm_X4 = np.linalg.norm(X1), np.linalg.norm(X2), np.linalg.norm(\n",
    "                    X3), np.linalg.norm(X4)\n",
    "\n",
    "                norms_X1.append(norm_X1)\n",
    "                norms_X2.append(norm_X2)\n",
    "                norms_X3.append(norm_X3)\n",
    "                norms_X4.append(norm_X4)\n",
    "\n",
    "            norms_X1, norms_X2, norms_X3, norms_X4 = np.array(norms_X1), np.array(norms_X2), np.array(norms_X3), np.array(norms_X4)\n",
    "\n",
    "            mean_X1, stdev_X1 = np.mean(norms_X1), np.std(norms_X1)\n",
    "            mean_X2, stdev_X2 = np.mean(norms_X2), np.std(norms_X2)\n",
    "            mean_X3, stdev_X3 = np.mean(norms_X3), np.std(norms_X3)\n",
    "            mean_X4, stdev_X4 = np.mean(norms_X4), np.std(norms_X4)\n",
    "\n",
    "            if Encoding == 'pca16':\n",
    "                f.write(\"PCA16 Encoding\\n\")\n",
    "            elif Encoding == 'autoencoder16':\n",
    "                f.write(\"autoencoder16 Encoding\\n\")\n",
    "            f.write(\"mean of X1: \" + str(mean_X1) + \" standard deviation of X1: \" + str(stdev_X1))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"mean of X2: \" + str(mean_X2) + \" standard deviation of X2: \" + str(stdev_X2))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"mean of X3: \" + str(mean_X3) + \" standard deviation of X3: \" + str(stdev_X3))\n",
    "            f.write(\"\\n\")\n",
    "            f.write(\"mean of X4: \" + str(mean_X4) + \" standard deviation of X4: \" + str(stdev_X4))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkoKAf4hLtkC"
   },
   "source": [
    "##Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NHd4OH8PLwve",
    "outputId": "926cfa0a-ade9-4eab-fff9-8609f5fb640c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4 resize256 with cross_entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahr\\anaconda3\\envs\\notebook\\Lib\\site-packages\\pennylane\\_grad.py:157: UserWarning: Attempted to differentiate a function with no trainable parameters. If this is unintended, please add trainable parameters via the 'requires_grad' attribute or 'argnum' keyword.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:  0  cost:  17.87436258530003\n",
      "iteration:  10  cost:  16.96731243431361\n",
      "iteration:  20  cost:  17.165908440817425\n",
      "iteration:  30  cost:  17.647412713683636\n",
      "iteration:  40  cost:  17.214381706713862\n",
      "iteration:  50  cost:  17.59742488569882\n",
      "iteration:  60  cost:  17.27696892194499\n",
      "iteration:  70  cost:  17.27787277632863\n",
      "iteration:  80  cost:  17.077196817348575\n",
      "iteration:  90  cost:  17.61594710511539\n",
      "iteration:  100  cost:  17.588864958684567\n",
      "iteration:  110  cost:  17.51036541352262\n",
      "iteration:  120  cost:  17.065580314961032\n",
      "iteration:  130  cost:  17.552995876523017\n",
      "iteration:  140  cost:  17.272682848336988\n",
      "iteration:  150  cost:  17.26650835129625\n",
      "iteration:  160  cost:  16.90976134972354\n",
      "iteration:  170  cost:  17.475081426862825\n",
      "iteration:  180  cost:  17.108624953064336\n",
      "iteration:  190  cost:  17.44561732755803\n",
      "Accuracy for U_SU4 resize256 :0.5155\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  18.676745174058816\n",
      "iteration:  10  cost:  18.45609598409594\n",
      "iteration:  20  cost:  16.990149530273364\n",
      "iteration:  30  cost:  17.31352481885291\n",
      "iteration:  40  cost:  17.340296848930997\n",
      "iteration:  50  cost:  17.794444546754182\n",
      "iteration:  60  cost:  16.368002268557856\n",
      "iteration:  70  cost:  18.36200890358103\n",
      "iteration:  80  cost:  18.39277547527886\n",
      "iteration:  90  cost:  17.802677927897296\n",
      "iteration:  100  cost:  15.940594429177217\n",
      "iteration:  110  cost:  17.001185563428994\n",
      "iteration:  120  cost:  18.52180599793995\n",
      "iteration:  130  cost:  18.05339387712018\n",
      "iteration:  140  cost:  20.429632006744406\n",
      "iteration:  150  cost:  20.159298131676685\n",
      "iteration:  160  cost:  16.81763781979977\n",
      "iteration:  170  cost:  16.273606416370683\n",
      "iteration:  180  cost:  18.920595505654024\n",
      "iteration:  190  cost:  16.477391791195505\n",
      "Accuracy for U_SU4_1D resize256 :0.5\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_SU4_no_pooling resize256 with cross_entropy\n",
      "iteration:  0  cost:  17.63839131861892\n",
      "iteration:  10  cost:  17.891860575774235\n",
      "iteration:  20  cost:  17.71955548470417\n",
      "iteration:  30  cost:  17.72485250505921\n",
      "iteration:  40  cost:  17.980446032554575\n",
      "iteration:  50  cost:  17.877948518491642\n",
      "iteration:  60  cost:  17.95313120578037\n",
      "iteration:  70  cost:  18.069843302161473\n",
      "iteration:  80  cost:  18.084691725894672\n",
      "iteration:  90  cost:  17.736306226865487\n",
      "iteration:  100  cost:  17.84777049813049\n",
      "iteration:  110  cost:  17.34861370611916\n",
      "iteration:  120  cost:  17.4228042750592\n",
      "iteration:  130  cost:  17.649138303502962\n",
      "iteration:  140  cost:  17.68550733515836\n",
      "iteration:  150  cost:  17.65721886710533\n",
      "iteration:  160  cost:  17.930989634222144\n",
      "iteration:  170  cost:  17.772637933512197\n",
      "iteration:  180  cost:  18.019547317096627\n",
      "iteration:  190  cost:  17.37445039131974\n",
      "Accuracy for U_SU4_no_pooling resize256 :0.404\n",
      "\n",
      "\n",
      "Loss History for QCNN circuits, U_9_1D resize256 with cross_entropy\n",
      "iteration:  0  cost:  17.597757175970784\n",
      "iteration:  10  cost:  16.704370848989843\n",
      "iteration:  20  cost:  16.392437415585793\n",
      "iteration:  30  cost:  16.28288908736213\n",
      "iteration:  40  cost:  16.369255720426853\n",
      "iteration:  50  cost:  16.65509005661785\n",
      "iteration:  60  cost:  16.698812661301886\n",
      "iteration:  70  cost:  16.11538203583544\n",
      "iteration:  80  cost:  17.569811832425348\n",
      "iteration:  90  cost:  16.995171353768573\n",
      "iteration:  100  cost:  17.229934144566208\n",
      "iteration:  110  cost:  16.39127702542383\n",
      "iteration:  120  cost:  16.357230970778954\n",
      "iteration:  130  cost:  16.320851427857313\n",
      "iteration:  140  cost:  18.02640877140611\n",
      "iteration:  150  cost:  16.366944488645757\n",
      "iteration:  160  cost:  16.55051352129664\n",
      "iteration:  170  cost:  17.206070540902807\n",
      "iteration:  180  cost:  17.50025012747944\n",
      "iteration:  190  cost:  16.093620816992825\n",
      "Accuracy for U_9_1D resize256 :0.674\n"
     ]
    }
   ],
   "source": [
    "# This generates the results of the bechmarking code\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Here are possible combinations of benchmarking user could try.\n",
    "Unitaries: ['U_TTN', 'U_5', 'U_6', 'U_9', 'U_13', 'U_14', 'U_15', 'U_SO4', 'U_SU4', 'U_SU4_no_pooling', 'U_SU4_1D', 'U_9_1D']\n",
    "U_num_params: [2, 10, 10, 2, 6, 6, 4, 6, 15, 15, 15, 2]\n",
    "Encodings: ['resize256', 'pca8', 'autoencoder8', 'pca16-compact', 'autoencoder16-compact', 'pca32-1', 'autoencoder32-1',\n",
    "            'pca16-1', 'autoencoder16-1', 'pca30-1', 'autoencoder30-1', 'pca12-1', 'autoencoder12-1']\n",
    "dataset: 'mnist' or 'fashion_mnist'\n",
    "circuit: 'QCNN' or 'Hierarchical'\n",
    "cost_fn: 'mse' or 'cross_entropy'\n",
    "Note: when using 'mse' as cost_fn binary=\"True\" is recommended, when using 'cross_entropy' as cost_fn must be binary=\"False\".\n",
    "\"\"\"\n",
    "\n",
    "Unitaries = ['U_SU4', 'U_SU4_1D', 'U_SU4_no_pooling', 'U_9_1D']\n",
    "U_num_params = [15, 15, 15, 2]\n",
    "Encodings = ['resize256']\n",
    "dataset = 'fashion_mnist'\n",
    "classes = [0,1]\n",
    "binary = False\n",
    "cost_fn = 'cross_entropy'\n",
    "\n",
    "Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='QCNN', cost_fn=cost_fn, binary=binary)\n",
    "#Benchmarking.Benchmarking(dataset, classes, Unitaries, U_num_params, Encodings, circuit='Hierarchical', cost_fn=cost_fn, binary=binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
